{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "   DataTweet\n",
    "</h1>\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "    AUTOR:Luis Enrique Seijas Salomon<br>\n",
    "    FECHA: Septiembre 2021<br>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataTweet\n",
    "Es una aplicaci칩n que extrae informaci칩n a tiempo real de Twitter a trav칠s del Api que Twitter tiene a disposici칩n. La idea de esta aplicaci칩n es realizar la extracci칩n de datos de inter칠s sin necesidad de tener conocimientos sobre el funcionamiento de api de Twitter, ni grandes conocimientos como realizar conexiones y peticiones GET y POST en protocolos HTTP, quedando al alcance de todo tipo de usuarios.\n",
    "\n",
    "Esta aplicaci칩n provee una capa de abstracci칩n, que, con seguir una serie de pasos ya podemos extraer datos de inter칠s de la plataforma sin necesidad de ser expertos en el tema.\n",
    "\n",
    "Los detalles se pueden consultar en la documentaci칩n asociada al repositorio.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librer칤as y paquetes a instalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji_extractor\n",
    "!pip install emoji\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install jupyter-dash\n",
    "!pip install dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de librer칤as implementadas\n",
    "\n",
    "Para el desarrollo de la herramienta se realiz칩 en lenguaje programaci칩n Python, bajo el entorno de desarrollo, j칰piter notebook.  En dicho desarrollo se hicieron usa de m칰ltiples Librer칤a de Python como :\n",
    "\n",
    "- Pandas: Usada para creaci칩n y exportaci칩n de las tablas donde se almacenan los datos extra칤dos.\n",
    "- Reguests: Usada para establecer la comunicaci칩n entre la herramienta y el API de Twitter mediante peticiones HTTP (GET y POST).\n",
    "- NLTK,Spacy,en_core_web_sm,emoji_extractor: estas Liberia se usaron para un procesado previo de los datos antes de exportar el dataset final, el cual consiste en separar emojis en casa de que existan, as칤 como analizar el grado de neutralidad, negatividad y positividad de los mismos, tambi칠n un proceso de eliminaci칩n de signos de puntuaci칩n, separaci칩n de cada palabras y lematizaci칩n de las mismas, con la finalidad de aportar metadatos de los datos recolectados para procesos de an치lisis posteriores.  \n",
    "- Dash: Usada para implementar la interfaz gr치fica en lenguaje HTML mediante lenguaje Python, esta herramienta permite la visualizaci칩n din치mica de datos. En este proyecto se implement칩 esta librer칤a para la creaci칩n de una peque침a interfaz de usuario para facilitar el uso de la herramienta. Conjuntamente con esta librer칤a se usaron otros paquetes como: dash_bootstrap_components, para la implementaci칩n de estilos gr치ficos y jupyter_dash para implementaci칩n de la interfaz desde el entorno de desarrollo j칰piter notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from emoji_extractor.extract import Extractor\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import es_core_news_sm\n",
    "\n",
    "import plotly.express as px\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State, MATCH, ALL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Api Twitter\n",
    "\n",
    "Se establecen los par치metros de configuraci칩n para la comunicaci칩n con el API de Twitter, los endpoint usados son los de extracci칩n de datos a tiempo real.\n",
    "\n",
    "Par치metros de configuraci칩n del API Twitter (Endpoint)\n",
    "\n",
    "Se puede consultar documentaci칩n en: https://developer.twitter.com/en/docs/twitter-api/tweets/filtered-stream/api-reference/get-tweets-search-stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_url=\"https://api.twitter.com/2/tweets/search/stream\"\n",
    "rules_url=\"https://api.twitter.com/2/tweets/search/stream/rules\"\n",
    "user_url=\"https://api.twitter.com/2/users\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de conectividad y extracci칩n de datos con el API de Twitter\n",
    "\n",
    "Las reglas de extracci칩n de datos son un conjunto de par치metros mediante el cual nos comunicamos con el API para obtener la mayor cantidad de tweet de nuestro inter칠s, actualmente existen m칰ltiples reglas para definir la b칰squeda y extracci칩n de los datos, las cuales se rigen bajo una sintaxis espec칤fica establecida en la documentaci칩n oficial de Twitter.\n",
    "\n",
    "Debido a que las reglas se rigen por una sintaxis definida, las cu치les no son del todo sencillas, por lo cual,  se crearon un conjunto de funciones que facilitan la implementaci칩n de las mismas.\n",
    "\n",
    "Dentro de las funciones que facilitan la creaci칩n de reglas se encuentran:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GuardarToken(token,user=\"\"):\n",
    "    \"\"\"\n",
    "        Esta funci칩n almacena las credenciales del usuario un fichero .json\n",
    "        Par치metros:\n",
    "          token: string\n",
    "            Token de validaci칩n\n",
    "          user: string\n",
    "              Nombre de usuario para comprobar la validez de token\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          No retorna nada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> GuardarToken(\"xxxxxxxxx...xxxxxxxxxxxx...\",user=\"@nombreUser\")\n",
    "    \"\"\"\n",
    "    jsonFile = open(\"Credenciales.json\", \"w\")\n",
    "    jsonFile.write('{')\n",
    "    jsonFile.write('\"user\": \"'+user+'\",')\n",
    "    jsonFile.write('\"token\": \"'+token+'\"')\n",
    "    jsonFile.write('}')\n",
    "    jsonFile.close()\n",
    "            \n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "        Esta funci칩n permite la autenticaci칩n con el API de Twitter\n",
    "        Par치metros:\n",
    "          r: request\n",
    "    \"\"\"\n",
    "    with open(\"Credenciales.json\") as tokenfile:\n",
    "        tokenData = json.load(tokenfile)\n",
    "        r.headers[\"Authorization\"] = f'Bearer {tokenData[\"token\"]}'\n",
    "        r.headers[\"User-Agent\"] = \"ExtractorData\"\n",
    "        return r\n",
    "\n",
    "def crearReglas(rules_value, tag_value):\n",
    "    \"\"\"\n",
    "        Esta funci칩n permite crear las reglas, de tal forma que puedan ser interpretadas \n",
    "        por el API de Twitter\n",
    "        Par치metros:\n",
    "          rules_value: string\n",
    "            La cadena con todos los par치metros a formar la regla de b칰squeda\n",
    "          tag_value: string\n",
    "              Candena con el nombre identificador de la regla\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          Crear la regla directamente en la sesi칩n abierta del API de Twitter para el token indicado\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> crearReglas(\"(palabra)(from:nombreuser)\", \"NombreRegla\")\n",
    "              Busca tweets que contengan la palabra \"palabra\" y sean emitidos por el usuario \"nombreuser\"\n",
    "    \"\"\"\n",
    "    sample_rules = [{\"value\": rules_value,\"tag\": tag_value}]\n",
    "    payload = {\"add\": sample_rules}\n",
    "    response = requests.post(rules_url,auth=bearer_oauth,json=payload)\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Error al crear la regla (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "\n",
    "def obtenerReglas():\n",
    "    \"\"\"\n",
    "        Esta funci칩n obtiene las reglas actuales cargadas en la sesi칩n del API\n",
    "        Return\n",
    "          Diccionario de reglas\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerReglas()\n",
    "    \"\"\"\n",
    "    response = requests.get(rules_url, auth=bearer_oauth)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "def borrarReglas(rules):\n",
    "    \"\"\"\n",
    "        Esta funci칩n borra todas las reglas actuales cargadas en la sesi칩n del API\n",
    "        Par치metros:\n",
    "          rules: diccionario\n",
    "            Reglas cargas en la sesi칩n de Twitter\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          No retorna nada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> borrarReglas(obtenerReglas())\n",
    "    \"\"\"\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(rules_url,auth=bearer_oauth,json=payload)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "        \n",
    "def validarUsuario(user):\n",
    "    \"\"\"\n",
    "        Esta funci칩n valida que el usuario introducido sea v치lido y exista en Twitter\n",
    "        Par치metros:\n",
    "          user: string\n",
    "            Nombre de usuario puede ser con @ o sin ella.\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           Si existe o no el usuario : bool\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> validarUsuario(\"@nombreuser\")\n",
    "              True\n",
    "    \"\"\"\n",
    "    usernames = f\"usernames={user}\"\n",
    "    user_fields = \"user.fields=id,created_at\"  \n",
    "    response = requests.request(\"GET\", \"{}/by?{}&{}\".format(user_url,usernames,user_fields), auth=bearer_oauth,)\n",
    "    if response.status_code != 200:\n",
    "        return False\n",
    "    else:\n",
    "        if \"data\" in response.json():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def tweetUsuario(listaUsuario):\n",
    "    \"\"\"\n",
    "        Esta funci칩n formatea los nombres de usuarios para que el API de Twitter entienda\n",
    "        que se trata de un usuario a incluir en los criterios de b칰squeda\n",
    "        Par치metros:\n",
    "          listaUsuario: List\n",
    "            Lista de usuarios\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryUsuarios: List<string>\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetUsuario([\"@nombreuser\",\"@nombreuser2\"])\n",
    "                  [\"from:nombreuser\",\"from:nombreuser2\"]\n",
    "    \"\"\"\n",
    "    queryUsuarios = []\n",
    "    for user in listaUsuario:\n",
    "        if \"@\" in user:\n",
    "            user = user.replace(\"@\",\"\")\n",
    "        if validarUsuario(user):\n",
    "            queryUsuarios.extend([f\"from:{user}\"])\n",
    "    return queryUsuarios\n",
    "\n",
    "def tweetIdioma(idioma):\n",
    "    \"\"\"\n",
    "        Esta funci칩n formatea el idioma indicado para que el API de Twitter entienda\n",
    "        que se solo va a buscar tweets que sean emitidos en ese idioma\n",
    "\n",
    "        Par치metros:\n",
    "          idioma: string\n",
    "            idioma del tweet (\"es\",\"en\")\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryIdiomas: List<string>\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> queryIdiomas([\"es\"])\n",
    "                  [\"lang: es\"]\n",
    "    \"\"\"\n",
    "    queryIdiomas=\"\"\n",
    "    listaIdiomasPermitidos = [\"es\",\"en\"] # esta lista se puede cargar por configuraci칩n\n",
    "    if idioma in listaIdiomasPermitidos:\n",
    "        queryIdiomas=\"lang:{}\".format(idioma)        \n",
    "    return queryIdiomas\n",
    "\n",
    "def tweetExcluir(valor):\n",
    "    \"\"\"\n",
    "        Esta funci칩n es de prop칩sito general formatea cualquier par치metro para negarlo y que \n",
    "        sea omitido en la b칰squeda de Tweet\n",
    "        Par치metros:\n",
    "          valor: string\n",
    "            Cadena de texto de cualquier par치metro a omitir\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           string\n",
    "                Retorna la negaci칩n formateada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetExcluir(\"from:nombreuser\")\n",
    "                  -from:nombreuser\n",
    "                  En este caso se le pasa como par치metro un nombre de usuario y se niega, esto es interpretado en \n",
    "                  el api como : extraer todos los tweets que no sean de este usuario\n",
    "    \"\"\"\n",
    "    return \"-{}\".format(valor)\n",
    "\n",
    "def tweetRetweet(opcion=True):\n",
    "    \"\"\"\n",
    "        Esta funci칩n permite obtener Retweet o no\n",
    "        Par치metros:\n",
    "          opcion: bool\n",
    "            Si se desea o no retweet en la b칰squeda, por defecto viene a true\n",
    "            (True -> Estraer tweet y retweet | False -> Solo Tweet)\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           retweet: string\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetRetweet(opcion=false)\n",
    "                  -is:retweet\n",
    "    \"\"\"\n",
    "    retweet=\"is:retweet\"\n",
    "    if opcion == True:\n",
    "        return retweet\n",
    "    else:\n",
    "        return tweetExcluir(retweet)\n",
    "    \n",
    "def excluirPalabras(listaPalabras):\n",
    "    \"\"\"\n",
    "        Esta funci칩n excluye una lista de palabras\n",
    "        Par치metros:\n",
    "          listaPalabras: list<string>\n",
    "            Lista de palabras a excluir en la b칰squeda\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryPalabrasExcluidas: list<string>\n",
    "               lista de palabras formateadas a ser excluidas en la b칰squeda\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> excluirPalabras([\"palabra1\",\"palabra2\"])\n",
    "                  [\"-palabra1\",\"-palabra2\"]\n",
    "    \"\"\"\n",
    "    contadorPalabras=0\n",
    "    queryPalabrasExcluidas = \"\"\n",
    "    for palabra in listaPalabras:\n",
    "        if \" \" in palabra:\n",
    "            #Es una frase, hay que exlcuir la frase completa\n",
    "            conjuntoPalabras=\"({})\".format(palabra)\n",
    "            queryPalabrasExcluidas+=\"{}\".format(tweetExcluir(conjuntoPalabras))\n",
    "        else:    \n",
    "            queryPalabrasExcluidas+=\"{}\".format(tweetExcluir(palabra))\n",
    "        if contadorPalabras < len(listaPalabras)-1:\n",
    "            queryPalabrasExcluidas+=\" \"\n",
    "            contadorPalabras+=1\n",
    "            \n",
    "    return queryPalabrasExcluidas\n",
    "\n",
    "def agruparPalabras(cadenaPalabras):\n",
    "    \"\"\"\n",
    "        Esta funci칩n agrupa palabras para ser b칰squedas como grupos, se usa frecuente para buscar frases\n",
    "        Par치metros:\n",
    "          cadenaPalabras: string\n",
    "            Cadena de palabras\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           string\n",
    "               Cadena de palabras agrupadas\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> agruparPalabras(\"palabra1 palabra2\")\n",
    "                  (\"palabra1 palabra2\")\n",
    "    \"\"\"\n",
    "    return \"({})\".format(cadenaPalabras)\n",
    "\n",
    "\n",
    "def incluirPalabras(listaPalabras,logica=\" \"): #logica AND o OR\n",
    "    \"\"\"\n",
    "        Esta funci칩n Permite extracci칩n de Tweets que tengan un con juntos de palabras o \n",
    "        frases determinas, para esto, se recibe como par치metro una lista de palabras y \n",
    "        una opci칩n l칩gica (AND o OR,) lo que permite buscar tweet que tengan todas las palabras\n",
    "        indicadas (AND) o que contengan al menos una de las palabras indicadas (OR).\n",
    "        Par치metros:  \n",
    "          listaPalabras: list<string>\n",
    "            lista de palabras a incluir\n",
    "            logica : bool\n",
    "                AND - tweet que contengan todas las palabras indicadas.\n",
    "                OR  - tweet que contengan alemanes una de las palabras indicadas.\n",
    "                \" \" - si va vac칤o se interpreta como un OR\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryPalabras : list<string>\n",
    "               Lista de palabras\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> incluirPalabras([\"palabra1\",\"palabra2\"],logica=\"OR\")\n",
    "                  [\"palabra1 OR palabra2\"]\n",
    "    \"\"\"\n",
    "    queryPalabras = \"\"\n",
    "    contadorPalabras=0\n",
    "    if logica ==\"OR\" or logica ==\" \":\n",
    "        logica= \" OR \"\n",
    "        for palabra in listaPalabras:\n",
    "            queryPalabras+=\"{}\".format(palabra)\n",
    "            if contadorPalabras < len(listaPalabras)-1:\n",
    "                queryPalabras+=\"{}\".format(logica)\n",
    "                contadorPalabras+=1\n",
    "        return agruparPalabras(queryPalabras)\n",
    "    elif logica ==\"AND\":\n",
    "        for palabra in listaPalabras:\n",
    "            queryPalabras+=\"{}\".format(agruparPalabras(palabra))\n",
    "        return queryPalabras\n",
    "\n",
    "def obtenerTiempo(dias=0, minutos=0):\n",
    "    \"\"\"\n",
    "        Esta funci칩n obtiene el tiempo actual del sistema o el indicado, \n",
    "        se encarga obtener el valor de timeout y los tiempos de ejecuci칩n de la herramienta\n",
    "        \n",
    "        Par치metros:  \n",
    "          dias: int\n",
    "            N칰mero  de dias\n",
    "          minutos: int\n",
    "            N칰mero  de minutos\n",
    "         \n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           time : datatime\n",
    "               Tiempo\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerTiempo(dias=0, minutos=0)\n",
    "                  tiempo actual del sistema\n",
    "    \"\"\"\n",
    "    sumarTiempo=timedelta(0)\n",
    "    if dias!=0:\n",
    "        sumarTiempo=timedelta(dias)\n",
    "    if minutos!=0:\n",
    "        sumarTiempo=timedelta(minutes=minutos)\n",
    "    time = datetime.now()+sumarTiempo\n",
    "    return time\n",
    "\n",
    "def obtenerTweets(cantTweets=0,minutos=0,dias=0,timeoutMin=10):\n",
    "    \"\"\"\n",
    "        Esta funci칩n engloba todas las funciones, establece la comunican con el API para iniciar la extracci칩n de Tweets\n",
    "                \n",
    "        Par치metros:  \n",
    "          cantTweets: int\n",
    "              Cantidad de tweets que se desean extraer\n",
    "          minutos: int\n",
    "            Minutos que desean extraer Tweet\n",
    "          dias\n",
    "            N칰mero de d칤as que se desean estar extrayendo Tweet\n",
    "            timeoutMin: int\n",
    "                En caso de no encontrar ning칰n Tweet y si se le indica el par치metro de cantidad, el \n",
    "                programa finaliza la ejecuci칩n en el tiempo indicado, por defecto 10 min.\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           bool\n",
    "               Si el proceso termino correctamente o no\n",
    "            fichero json\n",
    "                Crea un fichero json con los datos del todos los tweets extra칤dos.\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerTweets(cantTweets=0,minutos=0,dias=0,timeoutMin=10)\n",
    "                  tiempo actual del sistema\n",
    "    \"\"\"\n",
    "    tiempoSalida=obtenerTiempo(dias=0,minutos=timeoutMin)\n",
    "    jsonFile = open(\"DataTweet.json\", \"w\")\n",
    "    jsonFile.write(\"[\")\n",
    "    DataDic={}\n",
    "    if cantTweets == 0 and minutos== 0 and dias==0:\n",
    "        cantTweets=100\n",
    "    auxCantTweets=0\n",
    "    tiempoFinalizacion=0\n",
    "    if minutos!=0 and dias==0:\n",
    "        tiempoFinalizacion=obtenerTiempo(minutos=minutos)\n",
    "    if dias!=0 and minutos==0:\n",
    "        tiempoFinalizacion=obtenerTiempo(dias=dias)\n",
    "    \n",
    "    tiempo=obtenerTiempo(minutos=minutos)\n",
    "    response = requests.get(stream_url, auth=bearer_oauth, stream=True,)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        print(\"error\")\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    for response_line in response.iter_lines():\n",
    "        if response_line:\n",
    "            jsonWrite=\"\"\n",
    "            json_response = json.loads(response_line)\n",
    "            jsonWrite=json.dumps(json_response)\n",
    "            if jsonWrite !=\"\":\n",
    "                #print(\"response_line:\"+json.dumps(json_response))\n",
    "                jsonFile.write(json.dumps(json_response))\n",
    "                if cantTweets != 0 and minutos == 0 and dias==0:\n",
    "                    if auxCantTweets < cantTweets-1:\n",
    "                        auxCantTweets+=1\n",
    "                        jsonFile.write(\",\")\n",
    "                        #print(json.dumps(json_response[\"data\"][\"text\"], indent=4, sort_keys=True))\n",
    "                        #print(\"\\n\")\n",
    "                    else:\n",
    "                        jsonFile.write(\"]\")\n",
    "                        jsonFile.close()\n",
    "                        return True\n",
    "                    \n",
    "                if minutos !=0 or dias!=0:\n",
    "                    if tiempoFinalizacion < obtenerTiempo():\n",
    "                        jsonFile.write(\"]\")\n",
    "                        jsonFile.close()\n",
    "                        return True\n",
    "                    else:\n",
    "                        jsonFile.write(\",\")\n",
    "                if obtenerTiempo() > tiempoSalida and cantTweets != 0 and (minutos ==0 or dias==0):\n",
    "                    jsonFile.write(\"]\")\n",
    "                    jsonFile.close()\n",
    "                    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de procesamiento y exportaci칩n de datos\n",
    "Una vez extra칤dos los datos desde el API, seg칰n los criterios de b칰squeda establecidos, es momento de realizar un procesamiento previo con la finalidad de limpiar un poco los datos y generar nuevos datos en base a los datos obtenidos.\n",
    "\n",
    "Los procesos incluidos en el procesamiento previos de los datos extra칤dos son:\n",
    "\n",
    "- Extracci칩n de emojis de Tweets.\n",
    "- C치lculo de puntaje de sentimientos de negatividad, positividad y neutralidad de emojis.\n",
    "- Eliminaci칩n de emojis de Tweets.\n",
    "- Eliminar signos de puntuaci칩n.\n",
    "- Tokenizaci칩n de palabras.\n",
    "- Eliminaci칩n de palabras vac칤as seg칰n idioma indicado (espa침ol o ingl칠s).\n",
    "- Lematizaci칩n.\n",
    "\n",
    "Para llevar a cabo cada proceso, se desarrollaron e implantaron un conjunto de funciones las cuales se dividieron en dos partes, funciones para procesamiento de emojis y funciones para procesamientos b치sicos de textos, dichas funciones se definen a continuaci칩n:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###                                           ### \n",
    " # Funciones de procesamiento b치sico de emojis #\n",
    "### \n",
    "\n",
    "def load_emoji_sentiment(path=\"Emoji_Sentiment_Data_v1.0\"):\n",
    "    \"\"\"\n",
    "        Esta funci칩n crea un diccionario de emojis con los scores de negativiad, positivad \n",
    "        y neutralidad, entre otros paramretros, de cada emoji del data set que recibe como parametro\n",
    "        Par치metros:\n",
    "          path: string\n",
    "            Ruta del fichero de dataset de emojis\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          emoji_dict : Diccionario\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> emoji_sent_dict = load_emoji_sentiment(\"Emoji_Sentiment_Data_v1.0.csv\")\n",
    "          >>> emoji_sent_dict[\"游땴\"]\n",
    "              {\n",
    "                'Negative': 0.4364820846905538,\n",
    "                'Neutral': 0.22041259500542887,\n",
    "                'Occurrences': 5526,\n",
    "                'Position': 0.803351976,\n",
    "                'Positive': 0.34310532030401736,\n",
    "                'Unicode block': 'Emoticons',\n",
    "                'Unicode codepoint': '0x1f62d',\n",
    "                'Unicode name': 'LOUDLY CRYING FACE'\n",
    "              }\n",
    "    \"\"\"\n",
    "    # Cargamos el csv de emoji_sentiment\n",
    "    emoji_sent_df = pd.read_csv(path,sep=\",\")\n",
    "    # Calculamos los scores dividiendo el n칰mero de emojis negativos y entre el total\n",
    "    emoji_sent_df[\"Negative\"] = emoji_sent_df[\"Negative\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    emoji_sent_df[\"Neutral\"] = emoji_sent_df[\"Neutral\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    emoji_sent_df[\"Positive\"] = emoji_sent_df[\"Positive\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    # Transformamos a dict\n",
    "    emoji_sent_df = emoji_sent_df.set_index('Emoji')\n",
    "    emoji_dict = emoji_sent_df.to_dict(orient=\"index\")\n",
    "    return emoji_dict\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\"\n",
    "      Esta funci칩n extrae emojis del texto en formato de lista, si el texto no tiene \n",
    "      emojis retorna una lista vacia.\n",
    "      Par치metros:\n",
    "        text: string\n",
    "          Texto con emojis\n",
    "      ----------------------------------------------------------------------------------   \n",
    "      Return\n",
    "        emojis_list : List\n",
    "      ----------------------------------------------------------------------------------\n",
    "      Ejemplo:\n",
    "        >>> extract_emojis(\"Texto de prueba 游꿭 游땨\")\n",
    "          ['游꿭', '游땨']\n",
    "    \"\"\"\n",
    "    extract = Extractor()\n",
    "    emojis = extract.count_emoji(text, check_first=False)\n",
    "    emojis_list = [key for key, _ in emojis.most_common()]\n",
    "    return emojis_list\n",
    "\n",
    "def get_emoji_sentiment(lista,sent_dict, option = \"positive\"):\n",
    "    \"\"\"\n",
    "      Esta funci칩n calcula el score del sentimento de una lista de emojis, los \n",
    "      sentinetimientos puedens ser positivo,negativo o neutral, \n",
    "      esta funcion se baja en un diccionario de score de emojis.\n",
    "      Par치metros:\n",
    "        lista: List\n",
    "          lista de emojis\n",
    "        sent_dict: diccionario\n",
    "          Diccionarios de score\n",
    "        option: string\n",
    "          Sentimento a buscar (positive,negative,neutral), sino se indica parametro \n",
    "          retorna sentimiento positivo\n",
    "      ----------------------------------------------------------------------------------   \n",
    "      Return\n",
    "        output : float\n",
    "      ----------------------------------------------------------------------------------\n",
    "      Ejemplo:\n",
    "        >>> get_emoji_sentiment(['游꿭', '游땨'],emoji_sent_dict, option = \"positive\")\n",
    "            0.8042328042328042\n",
    "    \"\"\"\n",
    "    output = 0\n",
    "    for emoji in lista:\n",
    "        try:\n",
    "            if option == \"positive\":\n",
    "                output = output + sent_dict[emoji][\"Positive\"]\n",
    "            elif option ==\"negative\":\n",
    "                output = output + sent_dict[emoji][\"Negative\"]\n",
    "            elif option ==\"neutral\":\n",
    "                output = output + sent_dict[emoji][\"Neutral\"]\n",
    "        except Exception as e: \n",
    "                continue\n",
    "    return output\n",
    "\n",
    "def clean_emoji(text):\n",
    "    \"\"\"\n",
    "        Esta funci칩n elimina los emojis de un texto. Es util porque podemos quere textos\n",
    "        sin emejis para mejorar el analisis.\n",
    "\n",
    "        Par치metros:\n",
    "          text: string\n",
    "            Texto con emojis\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          string2 : String\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> clean_emoji(\"Esto es un texto de prueba 游꿭, que contiene emojis 游땨\")\n",
    "              \"Esto es un texto de prueba  , que contiene emojis \" \n",
    "    \"\"\"\n",
    "\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "###                                           ### \n",
    " # Funciones de procesamiento b치sico de textos #\n",
    "###                                           ### \n",
    "\n",
    "def quitar_stopwords(tokens,lang=\"en\"): \n",
    "    \"\"\"\n",
    "        Esta funci칩n elimina los stop Word de una lista de tokens.\n",
    "        las stop Word tambi칠n conocidas en espa침ol \n",
    "        como palabras vac칤as (art칤culos, pronombres, preposiciones,etc). \n",
    "        Esta funcion es para eliminar palabras vac칤as en idioma ingles. (stopwords.words('english'))\n",
    "\n",
    "        Par치metros:\n",
    "            tokens: List\n",
    "                Lista de tokens\n",
    "            lang: string\n",
    "                idioma de las palabras, solo admite ingles y espa침ol\n",
    "        ---------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            filtered_sentence : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> quitar_stopwords(['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city'])\n",
    "            ['I', 'think', 'I', 'ever', 'city']\n",
    "    \"\"\"\n",
    "    if lang == \"es\":\n",
    "        idioma=\"spanish\"\n",
    "    else:\n",
    "        idioma=\"english\"\n",
    "    stop_words = set(stopwords.words(idioma)) \n",
    "    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "def quitar_puntuacion(tokens):\n",
    "    \"\"\"\n",
    "        Esta funci칩n elimina los signos de puntuacion presentes en un texto.\n",
    "        Retorna una lista de tokens sin signos de puntuaci칩n.\n",
    "        \n",
    "        Par치metros:\n",
    "            tokens: List\n",
    "            Lista de tokens\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            words : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> quitar_puntuacion(['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city', '.'])\n",
    "            ['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city']\n",
    "    \"\"\"\n",
    "    words=[word for word in tokens if word.isalnum()]\n",
    "    return words\n",
    "\n",
    "# Lematizar con Spacy\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "def lematizar(tokens,lang,nlp):\n",
    "    \"\"\"\n",
    "        Esta funci칩n lematiza una lista de tokens y retorna un string con las palabras lematizadas.\n",
    "        Es importante tener presente que hay que declarar antes del llamado a la funcion nlp con el modelo\n",
    "        pre-entrenado en lengaje que se desee lematizar y establecer los parametros que se requieran.\n",
    "        Esta funci칩n es una bajo la librer칤a de Spacy\n",
    "\n",
    "        INGLES\n",
    "        nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "        ESPA칌OL\n",
    "        nlp = es_core_news_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "        los paquetes pre-entrenados se descargar:\n",
    "            !python -m spacy download en_core_web_sm #Ingles\n",
    "            !python -m spacy download es_core_news_sm #Espa침ol\n",
    "\n",
    "        Par치metros:\n",
    "            tokens: List\n",
    "                Lista de tokens\n",
    "            lang: string\n",
    "                idioma de las palabras, solo admite ingles y espa침ol\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            words : string\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> lematizar(['rom', 'roms'])\n",
    "            \"rom rom\"\n",
    "    \"\"\"\n",
    "    if lang == \"es\":\n",
    "        nlp = es_core_news_sm.load(disable=['parser', 'ner'])\n",
    "    sentence = \" \".join(tokens)\n",
    "    mytokens = nlp(sentence)\n",
    "    # Lematizamos los tokens y los convertimos  a minusculas\n",
    "    mytokens = [ word.lemma_ if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    # Extraemos el text en una string\n",
    "    return \" \".join(mytokens)\n",
    "\n",
    "def tokenize(texto):\n",
    "    \"\"\"\n",
    "        Esta funci칩n tokeniza los registros, se usa el \"TweetTokenizer\" de \n",
    "        NLTK (https://github.com/jaredks/tweetokenize), el cual se usa para tokenizar registros \n",
    "        provenientes de la api de twitter, una vez tokenizado el texto retorna una lista de tokens.\n",
    "\n",
    "        Par치metros:\n",
    "          texto: string\n",
    "            Texto a tokenizar\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          tokens_list : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tokenize(\"I do not think I will ever be a city\")\n",
    "              ['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city']\n",
    "    \"\"\"\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    tokens_list = tweet_tokenizer.tokenize(texto)\n",
    "    return tokens_list\n",
    "\n",
    "\n",
    "def procesarTexto(dataset,lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Esta funci칩n ejecutar  ejecutar todas las funciones de procesamiento b치sico, tanto de emojis como de texto. \n",
    "        Par치metros:\n",
    "            dataset: dataframe\n",
    "                Datos a procesar\n",
    "            lang: string\n",
    "                Lengauje en el cual se van a procesar los datos\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            Dataset : dataframe\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> procesarTexto(dataset,\"es\")\n",
    "      \"\"\"\n",
    "    #Cargamos el dataset de score de sentimeintos de emojis y lo almacenamos en un diccionario\n",
    "    emoji_sent_dict = load_emoji_sentiment(\"Emoji_Sentiment_Data_v1.0.csv\")\n",
    "    \n",
    "    #Recorremos los registros para extraer los emoji que contengan cada registro (tweet)\n",
    "    dataset[\"emoji_list\"] = dataset[\"TextoOriginal\"].apply(lambda x: extract_emojis(x))\n",
    "    \n",
    "    #Extraemos los sentimentos positivos,negativos y neutrales de cada emoji que contengan los registros, partiendo del diccionarido de socre de sentimentos de emojis\n",
    "    dataset[\"sent_emoji_pos\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"positive\")) #sentimentos positivo\n",
    "    dataset[\"sent_emoji_neu\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"neutral\")) #sentimentos neutral\n",
    "    dataset[\"sent_emoji_neg\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"negative\")) #sentimentos negativo\n",
    "    \n",
    "    # Una vez extareido la informaci칩n de los emojis, los eliminamos de los registros.\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoOriginal\"].apply(lambda x: clean_emoji(x))\n",
    "    \n",
    "    # Procedemos a tokenizar los datos que tratamotamos anteriormente.\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: tokenize(x))\n",
    "    \n",
    "    # Eliminamos palabras vacias\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: quitar_stopwords(x))\n",
    "    \n",
    "    # Eliminamos los s칤mbolos de puntuaci칩n\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: quitar_puntuacion(x))\n",
    "    \n",
    "    # Lematizamos\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x:lematizar(x,lang,nlp))\n",
    "    return dataset\n",
    "\n",
    "def CrearTweetDataSet(nombreFichero):\n",
    "    \"\"\"\n",
    "        Pasar los datos dese un fichero .json a un dataframe\n",
    "        Par치metros:\n",
    "            nombreFichero: string\n",
    "                Nombre del fichero a cargar\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            Dataset\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> CrearTweetDataSet('DataTweet.json')\n",
    "      \"\"\"\n",
    "    #Cargamos los tweet que nos descargamos del fichero\n",
    "    tweetsData=\"\"\n",
    "    dataset = pd.DataFrame(columns=[\"TextoOriginal\",\"Regla\"])\n",
    "    with open(nombreFichero) as tweetsFile:\n",
    "        tweetsData = json.load(tweetsFile)\n",
    "    for info in tweetsData:\n",
    "        dataset=dataset.append({\"TextoOriginal\": info[\"data\"][\"text\"],\"Regla\": info[\"matching_rules\"][0][\"tag\"]},ignore_index=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "###                                    ### \n",
    " # Funciones de exportacion de fciheros #\n",
    "###                                    ###\n",
    "def exportToJSON(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto json\n",
    "        Par치metros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.json\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToJSON(leerFicheroDatos('DataTweet.json'),\"exportaJSON\")\n",
    "                exportaJSON.json\n",
    "      \"\"\"\n",
    "    dataframe.to_json(\"{}.json\".format(nombreFichero), orient='records')\n",
    "\n",
    "def exportToEXCEL(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto excel\n",
    "        Par치metros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.xlsx\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToEXCEL(leerFicheroDatos('DataTweet.json'),\"exportaEXCEL\")\n",
    "                exportaEXCEL.xlsx\n",
    "    \"\"\"\n",
    "    dataframe.to_excel(\"{}.xlsx\".format(nombreFichero), sheet_name='Datos')\n",
    "\n",
    "def exportToCSV(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto csv, con separador \"|\" (barra), \n",
    "        de esta forma permitimos comas (,) en le tweets\n",
    "        Par치metros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.csv\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToCSV(leerFicheroDatos('DataTweet.json'),\"exportaCSV\")\n",
    "                exportaCSV.csv\n",
    "    \"\"\"\n",
    "    dataframe.to_csv(\"{}.csv\".format(nombreFichero), sep = \"|\", index=False)\n",
    "    \n",
    "def exportToTXT(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "         Exportacion de dataframe en formto txt, con separador \"|\" (barra), \n",
    "        de esta forma permitimos comas (,) en le tweets\n",
    "        Par치metros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.txt\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToTXT(leerFicheroDatos('DataTweet.json'),\"exportaTXT\")\n",
    "            exportaCSV.txt\n",
    "    \"\"\"\n",
    "    dataframe.to_csv(\"{}.txt\".format(nombreFichero), sep = \"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecuci칩n desde consola\n",
    "\n",
    "Para este ejemplo de ejecuci칩n vamos a realizar un caso de uso, referente a un tema de actualidad.\n",
    "\n",
    "Se desea crear un dataset sobre acontecimientos recientes en la isla de la palma (Espa침a), debido a la erupci칩n del volc치n, con la finalidad de analizar la opini칩n de las personas sobre este hecho desde los tweet omitidos en Twitter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las credenciales para comunicarnos con el API\n",
    "GuardarToken(token=\"AAAAAA............EcHUFLY2wtvRGZ\",user=\"@nombreUsario\")\n",
    "\n",
    "#Definimos la variable para definir las reglas de b칰squeda\n",
    "queryRegla=\"\"\n",
    "\n",
    "# Primero, tenemos que listar las palabras, para esta caso vamos a crear una regla de b칰squeda que \n",
    "# contengas 3 listas de palabras\n",
    "\n",
    "#Lista 1 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluir1=[\"volcan\",\"gases toxicos\"]\n",
    "#Lista 2 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluir2=[\"volcan\",\"lava\"]\n",
    "#Lista 3 - Queremos obtener Tweet que al menos de estas palabras \n",
    "listaPalabrasIncluir3=[\"#LAPALMA\",\"#lapalma\",\"#LaPalma\",\"la Palma\",\"volcan\",\"lava\", \"vulcanologia\", \"erupci칩n\", \"gases toxicos\"]\n",
    "\n",
    "# Una vez definida las variables, procedemos formatar las palabras para poder extraer la informaci칩n deseada\n",
    "\n",
    "aux1=agruparPalabras(incluirPalabras(listaPalabrasIncluir1,\"AND\"))\n",
    "aux2=agruparPalabras(incluirPalabras(listaPalabrasIncluir2,\"AND\"))\n",
    "aux3=agruparPalabras(agruparPalabras(incluirPalabras(listaPalabrasIncluir3,\"OR\")))\n",
    "\n",
    "# Una vez formateadas todas las palabras, las agrupamos, con la finalidad de obtener tweets para cada caso\n",
    "\n",
    "queryRegla=agruparPalabras(incluirPalabras([aux1,aux2,aux3],\"OR\"))\n",
    "\n",
    "#Definimos el idioma en que se desea que aparezcan los tweet\n",
    "idioma = tweetIdioma(\"es\")\n",
    "queryRegla+=\" {}\".format(idioma)\n",
    "\n",
    "#Definimos si deseamos que aparezcan o no Retweet, para este caso no nos interesan\n",
    "retweet=tweetRetweet(False)\n",
    "queryRegla+=\" {}\".format(retweet)\n",
    "\n",
    "# Para definir los criterios de ejecuci칩n hay que decidir entre si se desean conseguir un n칰mero de tweet determinado o por tiempo\n",
    "# Debido a que estamos probando inicialmente la regla, vamos a iniciar por una configuraci칩n por tiempo,\n",
    "# ya que no sabemos si estas palabras tiene el tr치fico suficiente y de este modo vamos probando y ajustando la \n",
    "# la regla.\n",
    "\n",
    "CantTweet=0 # No queremos que sea por cantidad de Tweets, indicamos cero\n",
    "Dias=0 # No queremos que sean d칤as extrayendo de Tweets, indicamos cero\n",
    "\n",
    "# vamos a empezar por indicar que extraiga todos los tweet que pueda durante 1 minuto \n",
    "# seg칰n los criterios de b칰squeda establecidos.\n",
    "\n",
    "Min=1\n",
    "\n",
    "#Una vez definidos los criterios de b칰squeda, vamos a crear las reglas para iniciar el proceso de extracci칩n\n",
    "\n",
    "# Primero asignamos nombre a la regla, para identificarla\n",
    "nombreRegla1 = \"Regla Volcan #laPalma\"\n",
    "# Obtenemos todos las reglas que tiene la sesi칩n y las borramos para evitar que se solapen con reglas anteriores.\n",
    "reglas=obtenerReglas()\n",
    "borrarReglas(reglas)\n",
    "\n",
    "#Creamos la regla\n",
    "crearReglas(rules_value=queryRegla, tag_value=nombreRegla1)\n",
    "\n",
    "#Una vez definida la regla, procedemos a extraer los tweets\n",
    "obtenerTweets(cantTweets=CantTweet,minutos=Min,dias=Dias,timeoutMin=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si con los par치metros establecidos, logramos extraer algunos Tweets,\n",
    "# por defecto el nombre donde se guardan los tweets descargados se llama DataTweet.json\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez inspeccionados los datos, si vemos que hay datos que no pertenecen al contexto que necesitamos, probamos con seleccionar nuevas palabras u omitir a esos usuarios o palabras que no queremos que aparezcan en nuestra b칰squeda.\n",
    "\n",
    "Ahora mantendremos las palabras anteriores, pero a침adiremos otra regla, para eso definimos todos los criterios nuevamente como en la secci칩n anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la variable para definir las reglas de b칰squeda\n",
    "queryRegla2=\"\"\n",
    "\n",
    "# Listar las palabras que queremos que incluyan los tweets en la segunda regla\n",
    "#Lista 1 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluirR2=[\"volcan\",\"Cumbre\",\"Vieja\"]\n",
    "queryRegla2=agruparPalabras(incluirPalabras(listaPalabrasIncluirR2,\"AND\"))\n",
    "\n",
    "\n",
    "#Definimos el idioma en que se desea que aparezcan los tweet\n",
    "idioma = tweetIdioma(\"es\")\n",
    "queryRegla+=\" {}\".format(idioma)\n",
    "\n",
    "#Definimos si deseamos que aparezcan o no Retweet, para este caso no nos interesan\n",
    "retweet=tweetRetweet(False)\n",
    "queryRegla+=\" {}\".format(retweet)\n",
    "\n",
    "# Definimos los criterios de ejecuci칩n\n",
    "\n",
    "CantTweet=0 # No queremos que sea por cantidad de Tweets, indicamos cero\n",
    "Dias=0 # No queremos que sean d칤as extrayendo de Tweets, indicamos cero\n",
    "\n",
    "# vamos a empezar por indicar que extraiga todos los tweet que pueda durante 1 minuto \n",
    "# seg칰n los criterios de b칰squeda establecidos.\n",
    "\n",
    "Min=1\n",
    "\n",
    "#Una vez definidos los criterios de b칰squeda, vamos a crear las reglas para iniciar el proceso de extracci칩n\n",
    "\n",
    "# Primero asignamos nombre a la regla, para identificarla\n",
    "nombreRegla1 = \"Regla cumbre vieja\"\n",
    "\n",
    "#Creamos la regla y a침adimos a la lista de reglas, notece que no eleiminamos las reglas anteriores\n",
    "crearReglas(rules_value=queryRegla, tag_value=nombreRegla1)\n",
    "\n",
    "#Una vez definida la regla, procedemos a extraer los tweets\n",
    "obtenerTweets(cantTweets=CantTweet,minutos=Min,dias=Dias,timeoutMin=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si con los par치metros establecidos, logramos extraer algunos Tweets,\n",
    "# por defecto el nombre donde se guardan los tweets descargados se llama DataTweet.json\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como observamos que existe grafico para las palabras indicadas, procedemos hacer una petici칩n de 1000 tweets\n",
    "# o los que logre descargarse en los pr칩ximos 25 min\n",
    "\n",
    "Dias=0\n",
    "Min=0\n",
    "obtenerTweets(cantTweets=1000,minutos=Min,dias=Dias,timeoutMin=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez finalizado el proceso podemos observamos cuantos tweet logramos descargar y cargamos nuevamente los datos en un dataframe.\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar obtenemos un dataset con tweets referentes a los temas indicados, ahora queda el proceso de procesamiento y exportaci칩n de los datos, para futuros an치lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como podemos observar, obtuvimos alrededor de 600 tweet en 25 min, la gran mayor칤a referente al tema de inter칠s.\n",
    "\n",
    "# Continuamos con el procesamiento preliminar de los datos\n",
    "\n",
    "# Procesamos los datos extra칤dos\n",
    "dfProcesado=procesarTexto(df,\"es\")\n",
    "\n",
    "# Exportamos los datos en diferentes formatos, los cuales se almacenar치n en la ruta indicada, en este caso en la \n",
    "# misma donde se est치 ejecutando la aplicaci칩n\n",
    "exportToEXCEL(dfProcesado,\"Datos\")\n",
    "exportToCSV(dfProcesado,\"Datos\")\n",
    "exportToTXT(dfProcesado,\"Datos\")\n",
    "exportToJSON(dfProcesado,\"Datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaz Gr치fica\n",
    "El proceso de extracci칩n de datos, en tiempo real, desde el API de Twitter se puede realizar completamente desde el script del j칰piter notebook, implementando las funciones explicitadas anteriormente, sin embargo se desarroll칩 una peque침a interfaz para facilitar el proceso de interacci칩n entre la herramienta y el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_AWESOME = \"https://use.fontawesome.com/releases/v5.7.2/css/all.css\"\n",
    "app = JupyterDash(external_stylesheets=[dbc.themes.BOOTSTRAP,FONT_AWESOME], meta_tags=[{'name': 'viewport',\n",
    "                            'content': 'width=device-width, initial-scale=1.0'}])\n",
    "\n",
    "PLOTLY_LOGO = app.get_asset_url('logoHorizontal.png')\n",
    "\n",
    "Navbar = dbc.Navbar(\n",
    "    [\n",
    "        html.A(\n",
    "            dbc.Row([\n",
    "                dbc.Col(html.Img(src=PLOTLY_LOGO, height=\"55rem\"),className=\"p-1\"),\n",
    "                dbc.Col(dbc.NavbarBrand(\"\", className=\"ml-2\")),\n",
    "            ],align=\"Center\",no_gutters=True,),\n",
    "            href=\"\"),\n",
    "        dbc.Col([\n",
    "            dbc.Button(\" \",id=\"btnCredenciales\", color=\"primary\", className=\"fas fa-solid fa-lock\",n_clicks=0),\n",
    "            dbc.Modal(\n",
    "            [\n",
    "                dbc.ModalHeader(\"Token Auntenticaci칩n Twitter\"),\n",
    "                dbc.ModalBody([\n",
    "                    dbc.Input(id=\"tokenUser\", placeholder=\"Ingrese usuario twitter\", className=\"m-2\"),\n",
    "                    dbc.Input(id=\"token\", placeholder=\"Ingrese Token de autenticaci칩n\",className=\"m-2\"),\n",
    "                    html.Div(id='TokenValido',className=\"m-2 text-center\")\n",
    "                ]),\n",
    "                dbc.ModalFooter([\n",
    "                    dbc.Row([\n",
    "                        dbc.Button(\"Cerrar\", id=\"BtnCerrar\", color=\"danger\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        dbc.Button(\"Test\", id=\"BtnTest\", color=\"info\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        dbc.Button(\"Guardar\", id=\"BtnGuardar\", color=\"primary\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        \n",
    "                    ])                    \n",
    "                ]),\n",
    "            ],\n",
    "            id=\"modal\",\n",
    "            is_open=False,\n",
    "        ),\n",
    "        ],className=\"text-right\"),\n",
    "    ],\n",
    "    id=\"Navbar\",\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    ")\n",
    "@app.callback(\n",
    "    Output(\"modal\", \"is_open\"),\n",
    "    [Input(\"btnCredenciales\", \"n_clicks\"), Input(\"BtnCerrar\", \"n_clicks\"),Input(\"BtnGuardar\", \"n_clicks\")],\n",
    "    [State(\"modal\", \"is_open\"),State(\"token\", \"value\")],\n",
    ")\n",
    "def toggle_modal(btnCredenciales,BtnCerrar,BtnGuardar,is_open,token):\n",
    "    if BtnGuardar > 0:\n",
    "        if len(token):\n",
    "            GuardarToken(token)\n",
    "        return not is_open\n",
    "    elif btnCredenciales > 0 or BtnGuardar > 0:\n",
    "        return not is_open\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"TokenValido\", \"children\"),\n",
    "    [Input(\"BtnTest\", \"n_clicks\")],\n",
    "    [State(\"token\", \"value\"),State(\"tokenUser\", \"value\")],\n",
    ")\n",
    "def validarToken(BtnTest,token=\"\",tokenUser=\"\"):\n",
    "    if BtnTest > 0:\n",
    "        if token !=None and tokenUser !=None and len(token) > 0 and len(tokenUser) > 0:\n",
    "            GuardarToken(token,tokenUser)\n",
    "            if \"@\" in tokenUser:\n",
    "                tokenUser = tokenUser.replace(\"@\",\"\")\n",
    "            if validarUsuario(tokenUser):\n",
    "                return \"Token valido.\"\n",
    "            else:\n",
    "                return \"Token no valido.\"\n",
    "        return \"Introducir los datos solicitados.\"\n",
    "            \n",
    "#Componenetes parametros generales\n",
    "\n",
    "# idiomo\n",
    "idioma = dbc.Col([\n",
    "            dbc.Label(\"Idioma:\",html_for=\"lengtweet\",width=12, className=\"p-0\", style={\"fontSize\":\"16px\"}),\n",
    "            dbc.RadioItems(options=[{\"label\": \"Ingles\", \"value\": \"en\"},{\"label\": \"Espa침ol\", \"value\": \"es\"}],\n",
    "                value=\"en\",id=\"lengtweet\",inline=True)\n",
    "            ],width=6)\n",
    "\n",
    "# retweet\n",
    "retweet = dbc.Col([\n",
    "            dbc.Label(\"\", html_for=\"retweet\", width=12,className=\"p-0\"),\n",
    "            dbc.Checklist(options=[{\"label\": \"Retweets?\", \"value\": True}],value=False,id=\"retweet\",inline=True,switch=True)\n",
    "            ],width=6)\n",
    "\n",
    "#Periodicidad\n",
    "SelectorEjecucion = dbc.Col([\n",
    "                dbc.Label(\"Formas de ejecuc칤on:\", html_for=\"ejecucion\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[\n",
    "                        {\"label\": \"Cantidad de Tweets\", \"value\": 1},\n",
    "                        {\"label\": \"Tiempo de ejecuci칩n\", \"value\": 2},\n",
    "                    ],id=\"ejecucion\",placeholder=\"Seleccionar\")\n",
    "                ],width=12,style={\"paddingLeft\": \"15px\", \"marginTop\": \"15px\",\"marginBottom\":\"15px\"})\n",
    "@app.callback(\n",
    "    [Output('CantTweetCol', 'style'),Output('TiempoTweetCol', 'style')],\n",
    "    Input('ejecucion', 'value')\n",
    ")\n",
    "def MostrarTiempoEjecucion(value):\n",
    "    \"\"\"\n",
    "        Esta funci칩n muetra la forma de periodicidad que se desea ejecutar\n",
    "        Par치metros:\n",
    "                value: integer\n",
    "                    Indice asociado  la opcion selecionada (cantidad de tweets=1, timepo ejecucion = 2)\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                palabras :stylo para mostrar o ocultar el campo\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> MostrarTiempoEjecucion(1)\n",
    "                    [{\"display\": \"block\"},{\"display\": \"none\"}]\n",
    "    \"\"\"\n",
    "    if value == 1:\n",
    "        return [{\"display\": \"block\"},{\"display\": \"none\"}]\n",
    "    elif value == 2:\n",
    "        return [{\"display\": \"none\"},{\"display\": \"block\"}]\n",
    "    else:\n",
    "        return [{\"display\": \"none\"},{\"display\": \"none\"}]\n",
    "        \n",
    "\n",
    "#Cantidad de tweet\n",
    "cantidadTweet =dbc.Col([\n",
    "                    dbc.Label(\"Cantidad de Tweets:\", html_for=\"CantTweet\", width=12,className=\"p-0\"),\n",
    "                    dbc.Input(type=\"number\", id=\"CantTweet\", placeholder=\"0\",required=False,style={\"fontSize\":\"12px\"}),\n",
    "                ],width=12,style={\"display\": \"none\",\"marginTop\": \"10px\",\"marginBottom\":\"10px\"},id=\"CantTweetCol\")\n",
    "\n",
    "#Ejecuci칩n por tiempo\n",
    "TiempoTweet = dbc.Col([\n",
    "                    dbc.Label(\"Tiempo de ejecuci칩n:\", html_for=\"TiempoTweet\", width=12,className=\"p-0\"),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetDias\", placeholder=\"D칤as\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetHoras\", placeholder=\"Horas\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetMin\", placeholder=\"Min\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                    ],id=\"TiempoTweet\")\n",
    "                ],width=12, style={\"display\": \"none\",\"marginTop\": \"10px\",\"marginBottom\":\"10px\"},id=\"TiempoTweetCol\")\n",
    "\n",
    "#Formularios parametros generales \n",
    "formularioParamGenerales= dbc.FormGroup([\n",
    "                            dbc.Row([idioma,retweet,SelectorEjecucion,cantidadTweet,TiempoTweet],className=\"m-3\")\n",
    "                          ])\n",
    "\n",
    "CardformularioParamGenerales =dbc.Card([\n",
    "                dbc.CardHeader(\n",
    "                    html.H2(\n",
    "                        dbc.Button(f\"Parametros Generales\",color=\"link\",id={'type': 'btnReglaToggle','index': 54321},n_clicks=0,))),\n",
    "                        dbc.Collapse(formularioParamGenerales,id={'type': 'collapse','index': 54321},is_open=False,),\n",
    "            ])\n",
    "\n",
    "form = dbc.Form([CardformularioParamGenerales],)\n",
    "\n",
    "#Reglas\n",
    "# Formulario de reglas\n",
    "\n",
    "def CrearForm(i):\n",
    "    \"\"\"\n",
    "        Esta funci칩n define la estructura interna del formulario que comforma una regla.\n",
    "        Par치metros:\n",
    "                i: integer\n",
    "                Indice asociado a la regla recien creada.\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                palabras : Estructura HTML (string)\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> CrearForm(0)\n",
    "                    la salida es el HTML resultante, sutituyendo el valir de i pasado como parametro.\n",
    "    \"\"\"\n",
    "    palabras = dbc.Form([\n",
    "        dbc.FormGroup([\n",
    "            dbc.Label(\"Nombre regla:\", html_for={'type': 'NombreRegla','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\",id={'type': 'NombreRegla','index': i}, \n",
    "                    placeholder=\"Ingrese nombre de la regla\",style={\"fontSize\":\"12px\"}\n",
    "                ),width=12\n",
    "            ),\n",
    "            dbc.Label(\"Palabras a incluir:\", html_for={'type': 'palabrasIncluidas','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\", \n",
    "                          id={'type': 'palabrasIncluidas','index': i}, \n",
    "                          placeholder=\"Ingrese lista de palabras separadas por coma ','\",style={\"fontSize\":\"12px\"}\n",
    "                ),\n",
    "                width=12),\n",
    "            dbc.Label(\"Palabras a Excluir:\", html_for={'type': 'palabrasExcluidas','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\",id={'type': 'palabrasExcluidas','index': i},\n",
    "                          placeholder=\"Ingrese lista de palabras separadas por coma ','\",\n",
    "                          style={\"fontSize\":\"12px\"}\n",
    "                ),width=12,\n",
    "            ),\n",
    "            dbc.Row([\n",
    "                dbc.Button( \"Test\", id={'type': 'BtnProbarRegla','index': i},color=\"info\", className=\"mr-2\",n_clicks=0),\n",
    "                dbc.Button( \"Borrar\", id={'type': 'BtnBorrarRegla','index': i},color=\"danger\", className=\"mr-2\",n_clicks=0)\n",
    "            ],className=\"p-2\", style={\"marginLeft\":\"22rem\"}),\n",
    "            dbc.Col(html.Div(id={'type': 'SalidaRegla','index': i}),width=12)\n",
    "        ],row=True),\n",
    "    ],className=\"p-2\")\n",
    "    return palabras\n",
    "\n",
    "# callback crearRegla #\n",
    "# Permite probar치 cada una de las reglas haciendo click en el bot칩n BtnProbarRegla\n",
    "# que se encuentra dentro del formulario de cada regla, la finalidad es evaluar si \n",
    "# la regla funciona como es de esperar, en casa de que no podemos reajustar dicha regla\n",
    "# antes de procesar todo el conjunto para la creaci칩n del dataset final.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output({'type': 'SalidaRegla', 'index': MATCH}, 'children'),\n",
    "    Input({'type': 'BtnProbarRegla', 'index': MATCH}, \"n_clicks\"),\n",
    "    State({'type': 'NombreRegla', 'index': MATCH}, \"value\"),\n",
    "    State({'type': 'palabrasIncluidas', 'index': MATCH}, \"value\"),\n",
    "    State({'type': 'palabrasExcluidas', 'index': MATCH}, \"value\"),\n",
    ")\n",
    "def crearRegla(n_clicks,mombreRegla,palabrasIncluidas,palabrasExcluidas,lengtweet=\"en\",CantTweet=10,retweet=False):\n",
    "    if n_clicks > 0:\n",
    "        consulta=\"\"\n",
    "        if palabrasIncluidas !=None :\n",
    "            #Listas de palabras a buscar, es valido buscar por hashtag (#)\n",
    "            listaPalabras=palabrasIncluidas.split(\",\")\n",
    "            if len(listaPalabras) > 0 and listaPalabras !=None:\n",
    "                consulta=incluirPalabras(listaPalabras,\"OR\")\n",
    "\n",
    "        if palabrasExcluidas !=None :\n",
    "            # Lista de palabras a excluir\n",
    "            listaPalabrasExcluidas=palabrasExcluidas.split(\",\")\n",
    "            if len(listaPalabrasExcluidas) > 0:\n",
    "                consulta+=\" {}\".format(excluirPalabras(listaPalabrasExcluidas))\n",
    "\n",
    "            consulta+=\" {}\".format(tweetIdioma(lengtweet))\n",
    "            consulta+=\" {}\".format(tweetRetweet(retweet))\n",
    "            reglas=obtenerReglas()\n",
    "            borrarReglas(reglas)\n",
    "            crearReglas(rules_value=consulta, tag_value=mombreRegla)\n",
    "            obtenerTweets(cantTweets=CantTweet,minutos=0,dias=0)\n",
    "\n",
    "            return \"Finalizado\"\n",
    "\n",
    "\n",
    "def CrearListasReglas(i):\n",
    "    \"\"\"\n",
    "        Esta funci칩n define la estructura html para cada regla.\n",
    "        Par치metros:\n",
    "                i: integer\n",
    "                Indice asociado a la regla recine creada.\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                Estructura HTML (string)\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> CrearListasReglas(0)\n",
    "                    dbc.Card([\n",
    "                        dbc.CardHeader(\n",
    "                            html.H2(\n",
    "                                dbc.Button(f\"Regla #1\",color=\"link\",id={'type': 'btnReglaToggle','index': 1},n_clicks=0,))),\n",
    "                                dbc.Collapse(CrearForm(1),id={'type': 'collapse','index': 1},is_open=False,),])\n",
    "    \"\"\"\n",
    "    return dbc.Card([\n",
    "                dbc.CardHeader(\n",
    "                    html.H2(\n",
    "                        dbc.Button(f\"Regla {i+1}\",color=\"link\",id={'type': 'btnReglaToggle','index': i},n_clicks=0,))),\n",
    "                        dbc.Collapse(CrearForm(i),id={'type': 'collapse','index': i},is_open=False,),\n",
    "            ])\n",
    "\n",
    "# callback AddReglaAccordion #\n",
    "# A침ade un formulario de reglas nuevo.\n",
    "\n",
    "@app.callback(\n",
    "    Output('accordion-container', 'children'),\n",
    "    Input('AddRegla', 'n_clicks'),\n",
    "    State('accordion-container', 'children'))\n",
    "def AddReglaAccordion(n_clicks, children):\n",
    "    new_dropdown = CrearListasReglas(n_clicks)\n",
    "    children.append(new_dropdown)\n",
    "    return children\n",
    "\n",
    "# callback AbrirCerrarAccordion #\n",
    "# Funcionalidad netamente est칠tica para poder abrir o cerrar \n",
    "# las reglas creadas.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output({'type': 'collapse', 'index': MATCH}, \"is_open\"),\n",
    "    Input({'type': 'btnReglaToggle', 'index': MATCH}, \"n_clicks\"),\n",
    "    State({'type': 'collapse', 'index': MATCH}, \"is_open\"),\n",
    ")\n",
    "def AbrirCerrarAccordion(n_clicks,is_open):\n",
    "    if n_clicks > 0:\n",
    "        return not is_open\n",
    "\n",
    "# callback ProcesarRegla #\n",
    "# Toma todas reglas ya testadas, la procesa en el api de twitter,\n",
    "# para posteriormente generar el dataset seg칰n la data disponibles en este\n",
    "# momento en twitter.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('tabla-container','children'),Output('cargando','style')],\n",
    "    Input(\"BtnProcesar\", \"n_clicks\"),\n",
    "    State({'type': 'NombreRegla', 'index': ALL}, \"id\"),\n",
    "    State({'type': 'NombreRegla', 'index': ALL}, \"value\"),\n",
    "    State({'type': 'palabrasIncluidas', 'index': ALL}, \"value\"),\n",
    "    State({'type': 'palabrasExcluidas', 'index': ALL}, \"value\"),\n",
    "    State(\"lengtweet\", \"value\"),\n",
    "    State(\"retweet\", \"value\"),\n",
    "    State(\"CantTweet\", \"value\"),\n",
    "    State(\"TiempoTweetDias\", \"value\"),\n",
    "    State(\"TiempoTweetHoras\", \"value\"),\n",
    "    State(\"TiempoTweetMin\", \"value\"),\n",
    "    \n",
    ")\n",
    "def ProcesarRegla(n_clicks,nombreReglaID,nombreRegla,palabrasIncluidas,palabrasExcluidas,lengtweet,retweet,CantTweet=0,TiempoTweetDias=0,TiempoTweetHoras=0,TiempoTweetMin=0):\n",
    "    if n_clicks > 0:\n",
    "        \n",
    "        if retweet == [True]:\n",
    "            retweet=True\n",
    "        elif retweet == []:\n",
    "            retweet=False\n",
    "        \n",
    "        reglas=obtenerReglas()\n",
    "        borrarReglas(reglas)\n",
    "        for regla in nombreReglaID:\n",
    "            index=regla['index']\n",
    "            consulta=\"\"\n",
    "            if palabrasIncluidas[index] !=None :\n",
    "                #Listas de palabras a buscar, es valido buscar por hashtag (#)\n",
    "                listaPalabras=palabrasIncluidas[index].split(\",\")\n",
    "                if len(listaPalabras) > 0:\n",
    "                    consulta=incluirPalabras(listaPalabras,\"OR\")\n",
    "\n",
    "                # de esta forma se determinana las frases y van separadas por coma en caso de que se quieran incluir\n",
    "                #listafrases=[w for w in listaPalabrasExcluidas if \" \" in w]\n",
    "\n",
    "            if palabrasExcluidas[index] !=None :\n",
    "                # Lista de palabras a excluir\n",
    "                listaPalabrasExcluidas=palabrasExcluidas[index].split(\",\")\n",
    "                if len(listaPalabrasExcluidas) > 0:\n",
    "                    consulta+=\" {}\".format(excluirPalabras(listaPalabrasExcluidas))\n",
    "            \n",
    "            consulta+=\" {}\".format(tweetIdioma(lengtweet))\n",
    "            consulta+=\" {}\".format(tweetRetweet(retweet))\n",
    "            crearReglas(rules_value=consulta, tag_value=nombreRegla[index])\n",
    "        \n",
    "        if TiempoTweetHoras!= None and TiempoTweetHoras > 0 :\n",
    "            TiempoTweetMin=TiempoTweetSec*60\n",
    "        else:\n",
    "            TiempoTweetHoras=0\n",
    "            \n",
    "        if TiempoTweetMin == None:\n",
    "              TiempoTweetMin=0\n",
    "                \n",
    "        if TiempoTweetDias == None:\n",
    "              TiempoTweetDias=0\n",
    "        \n",
    "        if CantTweet == None:\n",
    "            Cantidad = 0\n",
    "                \n",
    "        obtenerTweets(cantTweets=CantTweet,minutos=TiempoTweetMin,dias=TiempoTweetDias,timeoutMin=10)\n",
    "        table = dbc.Table.from_dataframe(CrearTweetDataSet('DataTweet.json'), striped=True, \n",
    "                                         bordered=True, \n",
    "                                         hover=True,\n",
    "                                         responsive=True,\n",
    "                                         className=\"m-3\")\n",
    "        return [table,{\"display\": \"none\"}]\n",
    "    return[\"\",style_cargando]\n",
    "                 \n",
    "    \n",
    "##\n",
    "## CONTENT\n",
    "##\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cargando\", \"children\"),\n",
    "    [Input(\"BtnProcesar\", \"n_clicks\")]\n",
    ")\n",
    "def cargandoData(BtnProcesar):\n",
    "    if BtnProcesar > 0:\n",
    "        cargando=dbc.Spinner(color=\"primary\",spinner_style={\"width\": \"5rem\", \"height\": \"5rem\"})\n",
    "        return cargando\n",
    "\n",
    "    cargando=dbc.Spinner(color=\"primary\",spinner_style={\"width\": \"5rem\", \"height\": \"5rem\"})\n",
    "\n",
    "reglas = html.Div(id='accordion-container', children=[],className=\"\")\n",
    "Btn=dbc.Row([\n",
    "        dbc.Col([dbc.Button( \"Ejecutar\", id=\"BtnProcesar\",color=\"primary\", className=\"mr-2\",n_clicks=0,block=True)]),\n",
    "        dbc.Col([dbc.Button( \"A침adir Regla\", id=\"AddRegla\", className=\"mr-2\",n_clicks=0,block=True),]),\n",
    "        dbc.Col([dbc.Button( \"Exportar Ficheros\", id=\"BtnExportar\", className=\"mr-2\",n_clicks=0,block=True),]),\n",
    "    ],className=\"m-3\")\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"DivExportar\", \"children\"),\n",
    "    [Input(\"BtnExportar\", \"n_clicks\")]\n",
    ")\n",
    "def cargandoData(BtnExportar):\n",
    "    if BtnExportar > 0:\n",
    "        df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "        dfProcesado=procesarTexto(df,\"es\")\n",
    "        #Exportamos los datos en diferentes formatos\n",
    "        exportToEXCEL(dfProcesado,\"Datos\")\n",
    "        exportToCSV(dfProcesado,\"Datos\")\n",
    "        exportToTXT(dfProcesado,\"Datos\")\n",
    "        exportToJSON(dfProcesado,\"Datos\")\n",
    "        return \"Ficheros exportados correctamente\"\n",
    "\n",
    "style_cargando ={\n",
    "    \"height\": \"100vh\",\n",
    "    \"display\": \"flex\",\n",
    "    \"justifyContent\": \"center\",\n",
    "    \"alignItems\": \"center\",    \n",
    "}    \n",
    "\n",
    "content = dbc.Row([\n",
    "        dbc.Col([form,reglas,Btn],className=\"m-0 p-0\",width=4,style={\"backgroundColor\":\"#f8f8f8\", }),\n",
    "        dbc.Col([html.Div(id=\"DivExportar\"),html.Div(id='cargando',style=style_cargando),html.Div(id=\"tabla-container\",style={\"height\":\"100vh\", \"overflowY\": \"auto\",\"overflowX\": \"hidden\"})],width=8)\n",
    "    ],id=\"Content\",className=\"container-fluid\", style={\"height\":\"100vh\"})\n",
    "\n",
    "##\n",
    "## MAIN HTML\n",
    "##\n",
    "\n",
    "body = dbc.Container([Navbar,content], className=\"col-12 p-0\",style={\"height\":\"100%\", })\n",
    "app.layout=body\n",
    "\n",
    "# Run app and display result inline in the notebook\n",
    "#app.run_server(mode='inline')\n",
    "app.run_server(mode='external',debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
