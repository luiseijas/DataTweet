{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "   DataTweet\n",
    "</h1>\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "    AUTOR:Luis Enrique Seijas Salomon<br>\n",
    "    FECHA: Septiembre 2021<br>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataTweet\n",
    "Es una aplicación que extrae información a tiempo real de Twitter a través del Api que Twitter tiene a disposición. La idea de esta aplicación es realizar la extracción de datos de interés sin necesidad de tener conocimientos sobre el funcionamiento de api de Twitter, ni grandes conocimientos como realizar conexiones y peticiones GET y POST en protocolos HTTP, quedando al alcance de todo tipo de usuarios.\n",
    "\n",
    "Esta aplicación provee una capa de abstracción, que, con seguir una serie de pasos ya podemos extraer datos de interés de la plataforma sin necesidad de ser expertos en el tema.\n",
    "\n",
    "Los detalles se pueden consultar en la documentación asociada al repositorio.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías y paquetes a instalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji_extractor\n",
    "!pip install emoji\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install jupyter-dash\n",
    "!pip install dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de librerías implementadas\n",
    "\n",
    "Para el desarrollo de la herramienta se realizó en lenguaje programación Python, bajo el entorno de desarrollo, júpiter notebook.  En dicho desarrollo se hicieron usa de múltiples Librería de Python como :\n",
    "\n",
    "- Pandas: Usada para creación y exportación de las tablas donde se almacenan los datos extraídos.\n",
    "- Reguests: Usada para establecer la comunicación entre la herramienta y el API de Twitter mediante peticiones HTTP (GET y POST).\n",
    "- NLTK,Spacy,en_core_web_sm,emoji_extractor: estas Liberia se usaron para un procesado previo de los datos antes de exportar el dataset final, el cual consiste en separar emojis en casa de que existan, así como analizar el grado de neutralidad, negatividad y positividad de los mismos, también un proceso de eliminación de signos de puntuación, separación de cada palabras y lematización de las mismas, con la finalidad de aportar metadatos de los datos recolectados para procesos de análisis posteriores.  \n",
    "- Dash: Usada para implementar la interfaz gráfica en lenguaje HTML mediante lenguaje Python, esta herramienta permite la visualización dinámica de datos. En este proyecto se implementó esta librería para la creación de una pequeña interfaz de usuario para facilitar el uso de la herramienta. Conjuntamente con esta librería se usaron otros paquetes como: dash_bootstrap_components, para la implementación de estilos gráficos y jupyter_dash para implementación de la interfaz desde el entorno de desarrollo júpiter notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from emoji_extractor.extract import Extractor\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import es_core_news_sm\n",
    "\n",
    "import plotly.express as px\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State, MATCH, ALL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Api Twitter\n",
    "\n",
    "Se establecen los parámetros de configuración para la comunicación con el API de Twitter, los endpoint usados son los de extracción de datos a tiempo real.\n",
    "\n",
    "Parámetros de configuración del API Twitter (Endpoint)\n",
    "\n",
    "Se puede consultar documentación en: https://developer.twitter.com/en/docs/twitter-api/tweets/filtered-stream/api-reference/get-tweets-search-stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_url=\"https://api.twitter.com/2/tweets/search/stream\"\n",
    "rules_url=\"https://api.twitter.com/2/tweets/search/stream/rules\"\n",
    "user_url=\"https://api.twitter.com/2/users\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de conectividad y extracción de datos con el API de Twitter\n",
    "\n",
    "Las reglas de extracción de datos son un conjunto de parámetros mediante el cual nos comunicamos con el API para obtener la mayor cantidad de tweet de nuestro interés, actualmente existen múltiples reglas para definir la búsqueda y extracción de los datos, las cuales se rigen bajo una sintaxis específica establecida en la documentación oficial de Twitter.\n",
    "\n",
    "Debido a que las reglas se rigen por una sintaxis definida, las cuáles no son del todo sencillas, por lo cual,  se crearon un conjunto de funciones que facilitan la implementación de las mismas.\n",
    "\n",
    "Dentro de las funciones que facilitan la creación de reglas se encuentran:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GuardarToken(token,user=\"\"):\n",
    "    \"\"\"\n",
    "        Esta función almacena las credenciales del usuario un fichero .json\n",
    "        Parámetros:\n",
    "          token: string\n",
    "            Token de validación\n",
    "          user: string\n",
    "              Nombre de usuario para comprobar la validez de token\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          No retorna nada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> GuardarToken(\"xxxxxxxxx...xxxxxxxxxxxx...\",user=\"@nombreUser\")\n",
    "    \"\"\"\n",
    "    jsonFile = open(\"Credenciales.json\", \"w\")\n",
    "    jsonFile.write('{')\n",
    "    jsonFile.write('\"user\": \"'+user+'\",')\n",
    "    jsonFile.write('\"token\": \"'+token+'\"')\n",
    "    jsonFile.write('}')\n",
    "    jsonFile.close()\n",
    "            \n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "        Esta función permite la autenticación con el API de Twitter\n",
    "        Parámetros:\n",
    "          r: request\n",
    "    \"\"\"\n",
    "    with open(\"Credenciales.json\") as tokenfile:\n",
    "        tokenData = json.load(tokenfile)\n",
    "        r.headers[\"Authorization\"] = f'Bearer {tokenData[\"token\"]}'\n",
    "        r.headers[\"User-Agent\"] = \"ExtractorData\"\n",
    "        return r\n",
    "\n",
    "def crearReglas(rules_value, tag_value):\n",
    "    \"\"\"\n",
    "        Esta función permite crear las reglas, de tal forma que puedan ser interpretadas \n",
    "        por el API de Twitter\n",
    "        Parámetros:\n",
    "          rules_value: string\n",
    "            La cadena con todos los parámetros a formar la regla de búsqueda\n",
    "          tag_value: string\n",
    "              Candena con el nombre identificador de la regla\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          Crear la regla directamente en la sesión abierta del API de Twitter para el token indicado\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> crearReglas(\"(palabra)(from:nombreuser)\", \"NombreRegla\")\n",
    "              Busca tweets que contengan la palabra \"palabra\" y sean emitidos por el usuario \"nombreuser\"\n",
    "    \"\"\"\n",
    "    sample_rules = [{\"value\": rules_value,\"tag\": tag_value}]\n",
    "    payload = {\"add\": sample_rules}\n",
    "    response = requests.post(rules_url,auth=bearer_oauth,json=payload)\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Error al crear la regla (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "\n",
    "def obtenerReglas():\n",
    "    \"\"\"\n",
    "        Esta función obtiene las reglas actuales cargadas en la sesión del API\n",
    "        Return\n",
    "          Diccionario de reglas\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerReglas()\n",
    "    \"\"\"\n",
    "    response = requests.get(rules_url, auth=bearer_oauth)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "def borrarReglas(rules):\n",
    "    \"\"\"\n",
    "        Esta función borra todas las reglas actuales cargadas en la sesión del API\n",
    "        Parámetros:\n",
    "          rules: diccionario\n",
    "            Reglas cargas en la sesión de Twitter\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          No retorna nada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> borrarReglas(obtenerReglas())\n",
    "    \"\"\"\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(rules_url,auth=bearer_oauth,json=payload)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "        \n",
    "def validarUsuario(user):\n",
    "    \"\"\"\n",
    "        Esta función valida que el usuario introducido sea válido y exista en Twitter\n",
    "        Parámetros:\n",
    "          user: string\n",
    "            Nombre de usuario puede ser con @ o sin ella.\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           Si existe o no el usuario : bool\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> validarUsuario(\"@nombreuser\")\n",
    "              True\n",
    "    \"\"\"\n",
    "    usernames = f\"usernames={user}\"\n",
    "    user_fields = \"user.fields=id,created_at\"  \n",
    "    response = requests.request(\"GET\", \"{}/by?{}&{}\".format(user_url,usernames,user_fields), auth=bearer_oauth,)\n",
    "    if response.status_code != 200:\n",
    "        return False\n",
    "    else:\n",
    "        if \"data\" in response.json():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def tweetUsuario(listaUsuario):\n",
    "    \"\"\"\n",
    "        Esta función formatea los nombres de usuarios para que el API de Twitter entienda\n",
    "        que se trata de un usuario a incluir en los criterios de búsqueda\n",
    "        Parámetros:\n",
    "          listaUsuario: List\n",
    "            Lista de usuarios\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryUsuarios: List<string>\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetUsuario([\"@nombreuser\",\"@nombreuser2\"])\n",
    "                  [\"from:nombreuser\",\"from:nombreuser2\"]\n",
    "    \"\"\"\n",
    "    queryUsuarios = []\n",
    "    for user in listaUsuario:\n",
    "        if \"@\" in user:\n",
    "            user = user.replace(\"@\",\"\")\n",
    "        if validarUsuario(user):\n",
    "            queryUsuarios.extend([f\"from:{user}\"])\n",
    "    return queryUsuarios\n",
    "\n",
    "def tweetIdioma(idioma):\n",
    "    \"\"\"\n",
    "        Esta función formatea el idioma indicado para que el API de Twitter entienda\n",
    "        que se solo va a buscar tweets que sean emitidos en ese idioma\n",
    "\n",
    "        Parámetros:\n",
    "          idioma: string\n",
    "            idioma del tweet (\"es\",\"en\")\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryIdiomas: List<string>\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> queryIdiomas([\"es\"])\n",
    "                  [\"lang: es\"]\n",
    "    \"\"\"\n",
    "    queryIdiomas=\"\"\n",
    "    listaIdiomasPermitidos = [\"es\",\"en\"] # esta lista se puede cargar por configuración\n",
    "    if idioma in listaIdiomasPermitidos:\n",
    "        queryIdiomas=\"lang:{}\".format(idioma)        \n",
    "    return queryIdiomas\n",
    "\n",
    "def tweetExcluir(valor):\n",
    "    \"\"\"\n",
    "        Esta función es de propósito general formatea cualquier parámetro para negarlo y que \n",
    "        sea omitido en la búsqueda de Tweet\n",
    "        Parámetros:\n",
    "          valor: string\n",
    "            Cadena de texto de cualquier parámetro a omitir\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           string\n",
    "                Retorna la negación formateada\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetExcluir(\"from:nombreuser\")\n",
    "                  -from:nombreuser\n",
    "                  En este caso se le pasa como parámetro un nombre de usuario y se niega, esto es interpretado en \n",
    "                  el api como : extraer todos los tweets que no sean de este usuario\n",
    "    \"\"\"\n",
    "    return \"-{}\".format(valor)\n",
    "\n",
    "def tweetRetweet(opcion=True):\n",
    "    \"\"\"\n",
    "        Esta función permite obtener Retweet o no\n",
    "        Parámetros:\n",
    "          opcion: bool\n",
    "            Si se desea o no retweet en la búsqueda, por defecto viene a true\n",
    "            (True -> Estraer tweet y retweet | False -> Solo Tweet)\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           retweet: string\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tweetRetweet(opcion=false)\n",
    "                  -is:retweet\n",
    "    \"\"\"\n",
    "    retweet=\"is:retweet\"\n",
    "    if opcion == True:\n",
    "        return retweet\n",
    "    else:\n",
    "        return tweetExcluir(retweet)\n",
    "    \n",
    "def excluirPalabras(listaPalabras):\n",
    "    \"\"\"\n",
    "        Esta función excluye una lista de palabras\n",
    "        Parámetros:\n",
    "          listaPalabras: list<string>\n",
    "            Lista de palabras a excluir en la búsqueda\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryPalabrasExcluidas: list<string>\n",
    "               lista de palabras formateadas a ser excluidas en la búsqueda\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> excluirPalabras([\"palabra1\",\"palabra2\"])\n",
    "                  [\"-palabra1\",\"-palabra2\"]\n",
    "    \"\"\"\n",
    "    contadorPalabras=0\n",
    "    queryPalabrasExcluidas = \"\"\n",
    "    for palabra in listaPalabras:\n",
    "        if \" \" in palabra:\n",
    "            #Es una frase, hay que exlcuir la frase completa\n",
    "            conjuntoPalabras=\"({})\".format(palabra)\n",
    "            queryPalabrasExcluidas+=\"{}\".format(tweetExcluir(conjuntoPalabras))\n",
    "        else:    \n",
    "            queryPalabrasExcluidas+=\"{}\".format(tweetExcluir(palabra))\n",
    "        if contadorPalabras < len(listaPalabras)-1:\n",
    "            queryPalabrasExcluidas+=\" \"\n",
    "            contadorPalabras+=1\n",
    "            \n",
    "    return queryPalabrasExcluidas\n",
    "\n",
    "def agruparPalabras(cadenaPalabras):\n",
    "    \"\"\"\n",
    "        Esta función agrupa palabras para ser búsquedas como grupos, se usa frecuente para buscar frases\n",
    "        Parámetros:\n",
    "          cadenaPalabras: string\n",
    "            Cadena de palabras\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           string\n",
    "               Cadena de palabras agrupadas\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> agruparPalabras(\"palabra1 palabra2\")\n",
    "                  (\"palabra1 palabra2\")\n",
    "    \"\"\"\n",
    "    return \"({})\".format(cadenaPalabras)\n",
    "\n",
    "\n",
    "def incluirPalabras(listaPalabras,logica=\" \"): #logica AND o OR\n",
    "    \"\"\"\n",
    "        Esta función Permite extracción de Tweets que tengan un con juntos de palabras o \n",
    "        frases determinas, para esto, se recibe como parámetro una lista de palabras y \n",
    "        una opción lógica (AND o OR,) lo que permite buscar tweet que tengan todas las palabras\n",
    "        indicadas (AND) o que contengan al menos una de las palabras indicadas (OR).\n",
    "        Parámetros:  \n",
    "          listaPalabras: list<string>\n",
    "            lista de palabras a incluir\n",
    "            logica : bool\n",
    "                AND - tweet que contengan todas las palabras indicadas.\n",
    "                OR  - tweet que contengan alemanes una de las palabras indicadas.\n",
    "                \" \" - si va vacío se interpreta como un OR\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           queryPalabras : list<string>\n",
    "               Lista de palabras\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> incluirPalabras([\"palabra1\",\"palabra2\"],logica=\"OR\")\n",
    "                  [\"palabra1 OR palabra2\"]\n",
    "    \"\"\"\n",
    "    queryPalabras = \"\"\n",
    "    contadorPalabras=0\n",
    "    if logica ==\"OR\" or logica ==\" \":\n",
    "        logica= \" OR \"\n",
    "        for palabra in listaPalabras:\n",
    "            queryPalabras+=\"{}\".format(palabra)\n",
    "            if contadorPalabras < len(listaPalabras)-1:\n",
    "                queryPalabras+=\"{}\".format(logica)\n",
    "                contadorPalabras+=1\n",
    "        return agruparPalabras(queryPalabras)\n",
    "    elif logica ==\"AND\":\n",
    "        for palabra in listaPalabras:\n",
    "            queryPalabras+=\"{}\".format(agruparPalabras(palabra))\n",
    "        return queryPalabras\n",
    "\n",
    "def obtenerTiempo(dias=0, minutos=0):\n",
    "    \"\"\"\n",
    "        Esta función obtiene el tiempo actual del sistema o el indicado, \n",
    "        se encarga obtener el valor de timeout y los tiempos de ejecución de la herramienta\n",
    "        \n",
    "        Parámetros:  \n",
    "          dias: int\n",
    "            Número  de dias\n",
    "          minutos: int\n",
    "            Número  de minutos\n",
    "         \n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           time : datatime\n",
    "               Tiempo\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerTiempo(dias=0, minutos=0)\n",
    "                  tiempo actual del sistema\n",
    "    \"\"\"\n",
    "    sumarTiempo=timedelta(0)\n",
    "    if dias!=0:\n",
    "        sumarTiempo=timedelta(dias)\n",
    "    if minutos!=0:\n",
    "        sumarTiempo=timedelta(minutes=minutos)\n",
    "    time = datetime.now()+sumarTiempo\n",
    "    return time\n",
    "\n",
    "def obtenerTweets(cantTweets=0,minutos=0,dias=0,timeoutMin=10):\n",
    "    \"\"\"\n",
    "        Esta función engloba todas las funciones, establece la comunican con el API para iniciar la extracción de Tweets\n",
    "                \n",
    "        Parámetros:  \n",
    "          cantTweets: int\n",
    "              Cantidad de tweets que se desean extraer\n",
    "          minutos: int\n",
    "            Minutos que desean extraer Tweet\n",
    "          dias\n",
    "            Número de días que se desean estar extrayendo Tweet\n",
    "            timeoutMin: int\n",
    "                En caso de no encontrar ningún Tweet y si se le indica el parámetro de cantidad, el \n",
    "                programa finaliza la ejecución en el tiempo indicado, por defecto 10 min.\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "           bool\n",
    "               Si el proceso termino correctamente o no\n",
    "            fichero json\n",
    "                Crea un fichero json con los datos del todos los tweets extraídos.\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> obtenerTweets(cantTweets=0,minutos=0,dias=0,timeoutMin=10)\n",
    "                  tiempo actual del sistema\n",
    "    \"\"\"\n",
    "    tiempoSalida=obtenerTiempo(dias=0,minutos=timeoutMin)\n",
    "    jsonFile = open(\"DataTweet.json\", \"w\")\n",
    "    jsonFile.write(\"[\")\n",
    "    DataDic={}\n",
    "    if cantTweets == 0 and minutos== 0 and dias==0:\n",
    "        cantTweets=100\n",
    "    auxCantTweets=0\n",
    "    tiempoFinalizacion=0\n",
    "    if minutos!=0 and dias==0:\n",
    "        tiempoFinalizacion=obtenerTiempo(minutos=minutos)\n",
    "    if dias!=0 and minutos==0:\n",
    "        tiempoFinalizacion=obtenerTiempo(dias=dias)\n",
    "    \n",
    "    tiempo=obtenerTiempo(minutos=minutos)\n",
    "    response = requests.get(stream_url, auth=bearer_oauth, stream=True,)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        print(\"error\")\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    for response_line in response.iter_lines():\n",
    "        if response_line:\n",
    "            jsonWrite=\"\"\n",
    "            json_response = json.loads(response_line)\n",
    "            jsonWrite=json.dumps(json_response)\n",
    "            if jsonWrite !=\"\":\n",
    "                #print(\"response_line:\"+json.dumps(json_response))\n",
    "                jsonFile.write(json.dumps(json_response))\n",
    "                if cantTweets != 0 and minutos == 0 and dias==0:\n",
    "                    if auxCantTweets < cantTweets-1:\n",
    "                        auxCantTweets+=1\n",
    "                        jsonFile.write(\",\")\n",
    "                        #print(json.dumps(json_response[\"data\"][\"text\"], indent=4, sort_keys=True))\n",
    "                        #print(\"\\n\")\n",
    "                    else:\n",
    "                        jsonFile.write(\"]\")\n",
    "                        jsonFile.close()\n",
    "                        return True\n",
    "                    \n",
    "                if minutos !=0 or dias!=0:\n",
    "                    if tiempoFinalizacion < obtenerTiempo():\n",
    "                        jsonFile.write(\"]\")\n",
    "                        jsonFile.close()\n",
    "                        return True\n",
    "                    else:\n",
    "                        jsonFile.write(\",\")\n",
    "                if obtenerTiempo() > tiempoSalida and cantTweets != 0 and (minutos ==0 or dias==0):\n",
    "                    jsonFile.write(\"]\")\n",
    "                    jsonFile.close()\n",
    "                    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de procesamiento y exportación de datos\n",
    "Una vez extraídos los datos desde el API, según los criterios de búsqueda establecidos, es momento de realizar un procesamiento previo con la finalidad de limpiar un poco los datos y generar nuevos datos en base a los datos obtenidos.\n",
    "\n",
    "Los procesos incluidos en el procesamiento previos de los datos extraídos son:\n",
    "\n",
    "- Extracción de emojis de Tweets.\n",
    "- Cálculo de puntaje de sentimientos de negatividad, positividad y neutralidad de emojis.\n",
    "- Eliminación de emojis de Tweets.\n",
    "- Eliminar signos de puntuación.\n",
    "- Tokenización de palabras.\n",
    "- Eliminación de palabras vacías según idioma indicado (español o inglés).\n",
    "- Lematización.\n",
    "\n",
    "Para llevar a cabo cada proceso, se desarrollaron e implantaron un conjunto de funciones las cuales se dividieron en dos partes, funciones para procesamiento de emojis y funciones para procesamientos básicos de textos, dichas funciones se definen a continuación:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###                                           ### \n",
    " # Funciones de procesamiento básico de emojis #\n",
    "### \n",
    "\n",
    "def load_emoji_sentiment(path=\"Emoji_Sentiment_Data_v1.0\"):\n",
    "    \"\"\"\n",
    "        Esta función crea un diccionario de emojis con los scores de negativiad, positivad \n",
    "        y neutralidad, entre otros paramretros, de cada emoji del data set que recibe como parametro\n",
    "        Parámetros:\n",
    "          path: string\n",
    "            Ruta del fichero de dataset de emojis\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          emoji_dict : Diccionario\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> emoji_sent_dict = load_emoji_sentiment(\"Emoji_Sentiment_Data_v1.0.csv\")\n",
    "          >>> emoji_sent_dict[\"😭\"]\n",
    "              {\n",
    "                'Negative': 0.4364820846905538,\n",
    "                'Neutral': 0.22041259500542887,\n",
    "                'Occurrences': 5526,\n",
    "                'Position': 0.803351976,\n",
    "                'Positive': 0.34310532030401736,\n",
    "                'Unicode block': 'Emoticons',\n",
    "                'Unicode codepoint': '0x1f62d',\n",
    "                'Unicode name': 'LOUDLY CRYING FACE'\n",
    "              }\n",
    "    \"\"\"\n",
    "    # Cargamos el csv de emoji_sentiment\n",
    "    emoji_sent_df = pd.read_csv(path,sep=\",\")\n",
    "    # Calculamos los scores dividiendo el número de emojis negativos y entre el total\n",
    "    emoji_sent_df[\"Negative\"] = emoji_sent_df[\"Negative\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    emoji_sent_df[\"Neutral\"] = emoji_sent_df[\"Neutral\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    emoji_sent_df[\"Positive\"] = emoji_sent_df[\"Positive\"]/emoji_sent_df[\"Occurrences\"]\n",
    "    # Transformamos a dict\n",
    "    emoji_sent_df = emoji_sent_df.set_index('Emoji')\n",
    "    emoji_dict = emoji_sent_df.to_dict(orient=\"index\")\n",
    "    return emoji_dict\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\"\n",
    "      Esta función extrae emojis del texto en formato de lista, si el texto no tiene \n",
    "      emojis retorna una lista vacia.\n",
    "      Parámetros:\n",
    "        text: string\n",
    "          Texto con emojis\n",
    "      ----------------------------------------------------------------------------------   \n",
    "      Return\n",
    "        emojis_list : List\n",
    "      ----------------------------------------------------------------------------------\n",
    "      Ejemplo:\n",
    "        >>> extract_emojis(\"Texto de prueba 🎻 😡\")\n",
    "          ['🎻', '😡']\n",
    "    \"\"\"\n",
    "    extract = Extractor()\n",
    "    emojis = extract.count_emoji(text, check_first=False)\n",
    "    emojis_list = [key for key, _ in emojis.most_common()]\n",
    "    return emojis_list\n",
    "\n",
    "def get_emoji_sentiment(lista,sent_dict, option = \"positive\"):\n",
    "    \"\"\"\n",
    "      Esta función calcula el score del sentimento de una lista de emojis, los \n",
    "      sentinetimientos puedens ser positivo,negativo o neutral, \n",
    "      esta funcion se baja en un diccionario de score de emojis.\n",
    "      Parámetros:\n",
    "        lista: List\n",
    "          lista de emojis\n",
    "        sent_dict: diccionario\n",
    "          Diccionarios de score\n",
    "        option: string\n",
    "          Sentimento a buscar (positive,negative,neutral), sino se indica parametro \n",
    "          retorna sentimiento positivo\n",
    "      ----------------------------------------------------------------------------------   \n",
    "      Return\n",
    "        output : float\n",
    "      ----------------------------------------------------------------------------------\n",
    "      Ejemplo:\n",
    "        >>> get_emoji_sentiment(['🎻', '😡'],emoji_sent_dict, option = \"positive\")\n",
    "            0.8042328042328042\n",
    "    \"\"\"\n",
    "    output = 0\n",
    "    for emoji in lista:\n",
    "        try:\n",
    "            if option == \"positive\":\n",
    "                output = output + sent_dict[emoji][\"Positive\"]\n",
    "            elif option ==\"negative\":\n",
    "                output = output + sent_dict[emoji][\"Negative\"]\n",
    "            elif option ==\"neutral\":\n",
    "                output = output + sent_dict[emoji][\"Neutral\"]\n",
    "        except Exception as e: \n",
    "                continue\n",
    "    return output\n",
    "\n",
    "def clean_emoji(text):\n",
    "    \"\"\"\n",
    "        Esta función elimina los emojis de un texto. Es util porque podemos quere textos\n",
    "        sin emejis para mejorar el analisis.\n",
    "\n",
    "        Parámetros:\n",
    "          text: string\n",
    "            Texto con emojis\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          string2 : String\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> clean_emoji(\"Esto es un texto de prueba 🎻, que contiene emojis 😡\")\n",
    "              \"Esto es un texto de prueba  , que contiene emojis \" \n",
    "    \"\"\"\n",
    "\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "###                                           ### \n",
    " # Funciones de procesamiento básico de textos #\n",
    "###                                           ### \n",
    "\n",
    "def quitar_stopwords(tokens,lang=\"en\"): \n",
    "    \"\"\"\n",
    "        Esta función elimina los stop Word de una lista de tokens.\n",
    "        las stop Word también conocidas en español \n",
    "        como palabras vacías (artículos, pronombres, preposiciones,etc). \n",
    "        Esta funcion es para eliminar palabras vacías en idioma ingles. (stopwords.words('english'))\n",
    "\n",
    "        Parámetros:\n",
    "            tokens: List\n",
    "                Lista de tokens\n",
    "            lang: string\n",
    "                idioma de las palabras, solo admite ingles y español\n",
    "        ---------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            filtered_sentence : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> quitar_stopwords(['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city'])\n",
    "            ['I', 'think', 'I', 'ever', 'city']\n",
    "    \"\"\"\n",
    "    if lang == \"es\":\n",
    "        idioma=\"spanish\"\n",
    "    else:\n",
    "        idioma=\"english\"\n",
    "    stop_words = set(stopwords.words(idioma)) \n",
    "    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "def quitar_puntuacion(tokens):\n",
    "    \"\"\"\n",
    "        Esta función elimina los signos de puntuacion presentes en un texto.\n",
    "        Retorna una lista de tokens sin signos de puntuación.\n",
    "        \n",
    "        Parámetros:\n",
    "            tokens: List\n",
    "            Lista de tokens\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            words : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> quitar_puntuacion(['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city', '.'])\n",
    "            ['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city']\n",
    "    \"\"\"\n",
    "    words=[word for word in tokens if word.isalnum()]\n",
    "    return words\n",
    "\n",
    "# Lematizar con Spacy\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "def lematizar(tokens,lang,nlp):\n",
    "    \"\"\"\n",
    "        Esta función lematiza una lista de tokens y retorna un string con las palabras lematizadas.\n",
    "        Es importante tener presente que hay que declarar antes del llamado a la funcion nlp con el modelo\n",
    "        pre-entrenado en lengaje que se desee lematizar y establecer los parametros que se requieran.\n",
    "        Esta función es una bajo la librería de Spacy\n",
    "\n",
    "        INGLES\n",
    "        nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "        ESPAÑOL\n",
    "        nlp = es_core_news_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "        los paquetes pre-entrenados se descargar:\n",
    "            !python -m spacy download en_core_web_sm #Ingles\n",
    "            !python -m spacy download es_core_news_sm #Español\n",
    "\n",
    "        Parámetros:\n",
    "            tokens: List\n",
    "                Lista de tokens\n",
    "            lang: string\n",
    "                idioma de las palabras, solo admite ingles y español\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            words : string\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> lematizar(['rom', 'roms'])\n",
    "            \"rom rom\"\n",
    "    \"\"\"\n",
    "    if lang == \"es\":\n",
    "        nlp = es_core_news_sm.load(disable=['parser', 'ner'])\n",
    "    sentence = \" \".join(tokens)\n",
    "    mytokens = nlp(sentence)\n",
    "    # Lematizamos los tokens y los convertimos  a minusculas\n",
    "    mytokens = [ word.lemma_ if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    # Extraemos el text en una string\n",
    "    return \" \".join(mytokens)\n",
    "\n",
    "def tokenize(texto):\n",
    "    \"\"\"\n",
    "        Esta función tokeniza los registros, se usa el \"TweetTokenizer\" de \n",
    "        NLTK (https://github.com/jaredks/tweetokenize), el cual se usa para tokenizar registros \n",
    "        provenientes de la api de twitter, una vez tokenizado el texto retorna una lista de tokens.\n",
    "\n",
    "        Parámetros:\n",
    "          texto: string\n",
    "            Texto a tokenizar\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "          tokens_list : list\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "          >>> tokenize(\"I do not think I will ever be a city\")\n",
    "              ['I', 'do', 'not', 'think', 'I', 'will', 'ever', 'be', 'a', 'city']\n",
    "    \"\"\"\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    tokens_list = tweet_tokenizer.tokenize(texto)\n",
    "    return tokens_list\n",
    "\n",
    "\n",
    "def procesarTexto(dataset,lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Esta función ejecutar  ejecutar todas las funciones de procesamiento básico, tanto de emojis como de texto. \n",
    "        Parámetros:\n",
    "            dataset: dataframe\n",
    "                Datos a procesar\n",
    "            lang: string\n",
    "                Lengauje en el cual se van a procesar los datos\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            Dataset : dataframe\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> procesarTexto(dataset,\"es\")\n",
    "      \"\"\"\n",
    "    #Cargamos el dataset de score de sentimeintos de emojis y lo almacenamos en un diccionario\n",
    "    emoji_sent_dict = load_emoji_sentiment(\"Emoji_Sentiment_Data_v1.0.csv\")\n",
    "    \n",
    "    #Recorremos los registros para extraer los emoji que contengan cada registro (tweet)\n",
    "    dataset[\"emoji_list\"] = dataset[\"TextoOriginal\"].apply(lambda x: extract_emojis(x))\n",
    "    \n",
    "    #Extraemos los sentimentos positivos,negativos y neutrales de cada emoji que contengan los registros, partiendo del diccionarido de socre de sentimentos de emojis\n",
    "    dataset[\"sent_emoji_pos\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"positive\")) #sentimentos positivo\n",
    "    dataset[\"sent_emoji_neu\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"neutral\")) #sentimentos neutral\n",
    "    dataset[\"sent_emoji_neg\"] = dataset[\"emoji_list\"].apply(lambda x: get_emoji_sentiment(x,emoji_sent_dict,\"negative\")) #sentimentos negativo\n",
    "    \n",
    "    # Una vez extareido la información de los emojis, los eliminamos de los registros.\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoOriginal\"].apply(lambda x: clean_emoji(x))\n",
    "    \n",
    "    # Procedemos a tokenizar los datos que tratamotamos anteriormente.\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: tokenize(x))\n",
    "    \n",
    "    # Eliminamos palabras vacias\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: quitar_stopwords(x))\n",
    "    \n",
    "    # Eliminamos los símbolos de puntuación\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x: quitar_puntuacion(x))\n",
    "    \n",
    "    # Lematizamos\n",
    "    dataset[\"TextoProcesado\"] = dataset[\"TextoProcesado\"].apply(lambda x:lematizar(x,lang,nlp))\n",
    "    return dataset\n",
    "\n",
    "def CrearTweetDataSet(nombreFichero):\n",
    "    \"\"\"\n",
    "        Pasar los datos dese un fichero .json a un dataframe\n",
    "        Parámetros:\n",
    "            nombreFichero: string\n",
    "                Nombre del fichero a cargar\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            Dataset\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> CrearTweetDataSet('DataTweet.json')\n",
    "      \"\"\"\n",
    "    #Cargamos los tweet que nos descargamos del fichero\n",
    "    tweetsData=\"\"\n",
    "    dataset = pd.DataFrame(columns=[\"TextoOriginal\",\"Regla\"])\n",
    "    with open(nombreFichero) as tweetsFile:\n",
    "        tweetsData = json.load(tweetsFile)\n",
    "    for info in tweetsData:\n",
    "        dataset=dataset.append({\"TextoOriginal\": info[\"data\"][\"text\"],\"Regla\": info[\"matching_rules\"][0][\"tag\"]},ignore_index=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "###                                    ### \n",
    " # Funciones de exportacion de fciheros #\n",
    "###                                    ###\n",
    "def exportToJSON(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto json\n",
    "        Parámetros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.json\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToJSON(leerFicheroDatos('DataTweet.json'),\"exportaJSON\")\n",
    "                exportaJSON.json\n",
    "      \"\"\"\n",
    "    dataframe.to_json(\"{}.json\".format(nombreFichero), orient='records')\n",
    "\n",
    "def exportToEXCEL(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto excel\n",
    "        Parámetros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.xlsx\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToEXCEL(leerFicheroDatos('DataTweet.json'),\"exportaEXCEL\")\n",
    "                exportaEXCEL.xlsx\n",
    "    \"\"\"\n",
    "    dataframe.to_excel(\"{}.xlsx\".format(nombreFichero), sheet_name='Datos')\n",
    "\n",
    "def exportToCSV(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "        Exportacion de dataframe en formto csv, con separador \"|\" (barra), \n",
    "        de esta forma permitimos comas (,) en le tweets\n",
    "        Parámetros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.csv\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToCSV(leerFicheroDatos('DataTweet.json'),\"exportaCSV\")\n",
    "                exportaCSV.csv\n",
    "    \"\"\"\n",
    "    dataframe.to_csv(\"{}.csv\".format(nombreFichero), sep = \"|\", index=False)\n",
    "    \n",
    "def exportToTXT(dataframe,nombreFichero):\n",
    "    \"\"\"\n",
    "         Exportacion de dataframe en formto txt, con separador \"|\" (barra), \n",
    "        de esta forma permitimos comas (,) en le tweets\n",
    "        Parámetros:\n",
    "            dataframe: dataframe\n",
    "                Dataframe de los datos a exportar\n",
    "            nombreFichero\n",
    "        ----------------------------------------------------------------------------------   \n",
    "        Return\n",
    "            fichero <nombreFichero>.txt\n",
    "        ----------------------------------------------------------------------------------\n",
    "        Ejemplo:\n",
    "            >>> exportToTXT(leerFicheroDatos('DataTweet.json'),\"exportaTXT\")\n",
    "            exportaCSV.txt\n",
    "    \"\"\"\n",
    "    dataframe.to_csv(\"{}.txt\".format(nombreFichero), sep = \"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución desde consola\n",
    "\n",
    "Para este ejemplo de ejecución vamos a realizar un caso de uso, referente a un tema de actualidad.\n",
    "\n",
    "Se desea crear un dataset sobre acontecimientos recientes en la isla de la palma (España), debido a la erupción del volcán, con la finalidad de analizar la opinión de las personas sobre este hecho desde los tweet omitidos en Twitter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las credenciales para comunicarnos con el API\n",
    "GuardarToken(token=\"AAAAAA............EcHUFLY2wtvRGZ\",user=\"@nombreUsario\")\n",
    "\n",
    "#Definimos la variable para definir las reglas de búsqueda\n",
    "queryRegla=\"\"\n",
    "\n",
    "# Primero, tenemos que listar las palabras, para esta caso vamos a crear una regla de búsqueda que \n",
    "# contengas 3 listas de palabras\n",
    "\n",
    "#Lista 1 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluir1=[\"volcan\",\"gases toxicos\"]\n",
    "#Lista 2 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluir2=[\"volcan\",\"lava\"]\n",
    "#Lista 3 - Queremos obtener Tweet que al menos de estas palabras \n",
    "listaPalabrasIncluir3=[\"#LAPALMA\",\"#lapalma\",\"#LaPalma\",\"la Palma\",\"volcan\",\"lava\", \"vulcanologia\", \"erupción\", \"gases toxicos\"]\n",
    "\n",
    "# Una vez definida las variables, procedemos formatar las palabras para poder extraer la información deseada\n",
    "\n",
    "aux1=agruparPalabras(incluirPalabras(listaPalabrasIncluir1,\"AND\"))\n",
    "aux2=agruparPalabras(incluirPalabras(listaPalabrasIncluir2,\"AND\"))\n",
    "aux3=agruparPalabras(agruparPalabras(incluirPalabras(listaPalabrasIncluir3,\"OR\")))\n",
    "\n",
    "# Una vez formateadas todas las palabras, las agrupamos, con la finalidad de obtener tweets para cada caso\n",
    "\n",
    "queryRegla=agruparPalabras(incluirPalabras([aux1,aux2,aux3],\"OR\"))\n",
    "\n",
    "#Definimos el idioma en que se desea que aparezcan los tweet\n",
    "idioma = tweetIdioma(\"es\")\n",
    "queryRegla+=\" {}\".format(idioma)\n",
    "\n",
    "#Definimos si deseamos que aparezcan o no Retweet, para este caso no nos interesan\n",
    "retweet=tweetRetweet(False)\n",
    "queryRegla+=\" {}\".format(retweet)\n",
    "\n",
    "# Para definir los criterios de ejecución hay que decidir entre si se desean conseguir un número de tweet determinado o por tiempo\n",
    "# Debido a que estamos probando inicialmente la regla, vamos a iniciar por una configuración por tiempo,\n",
    "# ya que no sabemos si estas palabras tiene el tráfico suficiente y de este modo vamos probando y ajustando la \n",
    "# la regla.\n",
    "\n",
    "CantTweet=0 # No queremos que sea por cantidad de Tweets, indicamos cero\n",
    "Dias=0 # No queremos que sean días extrayendo de Tweets, indicamos cero\n",
    "\n",
    "# vamos a empezar por indicar que extraiga todos los tweet que pueda durante 1 minuto \n",
    "# según los criterios de búsqueda establecidos.\n",
    "\n",
    "Min=1\n",
    "\n",
    "#Una vez definidos los criterios de búsqueda, vamos a crear las reglas para iniciar el proceso de extracción\n",
    "\n",
    "# Primero asignamos nombre a la regla, para identificarla\n",
    "nombreRegla1 = \"Regla Volcan #laPalma\"\n",
    "# Obtenemos todos las reglas que tiene la sesión y las borramos para evitar que se solapen con reglas anteriores.\n",
    "reglas=obtenerReglas()\n",
    "borrarReglas(reglas)\n",
    "\n",
    "#Creamos la regla\n",
    "crearReglas(rules_value=queryRegla, tag_value=nombreRegla1)\n",
    "\n",
    "#Una vez definida la regla, procedemos a extraer los tweets\n",
    "obtenerTweets(cantTweets=CantTweet,minutos=Min,dias=Dias,timeoutMin=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si con los parámetros establecidos, logramos extraer algunos Tweets,\n",
    "# por defecto el nombre donde se guardan los tweets descargados se llama DataTweet.json\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez inspeccionados los datos, si vemos que hay datos que no pertenecen al contexto que necesitamos, probamos con seleccionar nuevas palabras u omitir a esos usuarios o palabras que no queremos que aparezcan en nuestra búsqueda.\n",
    "\n",
    "Ahora mantendremos las palabras anteriores, pero añadiremos otra regla, para eso definimos todos los criterios nuevamente como en la sección anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la variable para definir las reglas de búsqueda\n",
    "queryRegla2=\"\"\n",
    "\n",
    "# Listar las palabras que queremos que incluyan los tweets en la segunda regla\n",
    "#Lista 1 - Queremos obtener Tweet que contengan ambas palabras \n",
    "listaPalabrasIncluirR2=[\"volcan\",\"Cumbre\",\"Vieja\"]\n",
    "queryRegla2=agruparPalabras(incluirPalabras(listaPalabrasIncluirR2,\"AND\"))\n",
    "\n",
    "\n",
    "#Definimos el idioma en que se desea que aparezcan los tweet\n",
    "idioma = tweetIdioma(\"es\")\n",
    "queryRegla+=\" {}\".format(idioma)\n",
    "\n",
    "#Definimos si deseamos que aparezcan o no Retweet, para este caso no nos interesan\n",
    "retweet=tweetRetweet(False)\n",
    "queryRegla+=\" {}\".format(retweet)\n",
    "\n",
    "# Definimos los criterios de ejecución\n",
    "\n",
    "CantTweet=0 # No queremos que sea por cantidad de Tweets, indicamos cero\n",
    "Dias=0 # No queremos que sean días extrayendo de Tweets, indicamos cero\n",
    "\n",
    "# vamos a empezar por indicar que extraiga todos los tweet que pueda durante 1 minuto \n",
    "# según los criterios de búsqueda establecidos.\n",
    "\n",
    "Min=1\n",
    "\n",
    "#Una vez definidos los criterios de búsqueda, vamos a crear las reglas para iniciar el proceso de extracción\n",
    "\n",
    "# Primero asignamos nombre a la regla, para identificarla\n",
    "nombreRegla1 = \"Regla cumbre vieja\"\n",
    "\n",
    "#Creamos la regla y añadimos a la lista de reglas, notece que no eleiminamos las reglas anteriores\n",
    "crearReglas(rules_value=queryRegla, tag_value=nombreRegla1)\n",
    "\n",
    "#Una vez definida la regla, procedemos a extraer los tweets\n",
    "obtenerTweets(cantTweets=CantTweet,minutos=Min,dias=Dias,timeoutMin=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si con los parámetros establecidos, logramos extraer algunos Tweets,\n",
    "# por defecto el nombre donde se guardan los tweets descargados se llama DataTweet.json\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como observamos que existe grafico para las palabras indicadas, procedemos hacer una petición de 1000 tweets\n",
    "# o los que logre descargarse en los próximos 25 min\n",
    "\n",
    "Dias=0\n",
    "Min=0\n",
    "obtenerTweets(cantTweets=1000,minutos=Min,dias=Dias,timeoutMin=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez finalizado el proceso podemos observamos cuantos tweet logramos descargar y cargamos nuevamente los datos en un dataframe.\n",
    "\n",
    "df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar obtenemos un dataset con tweets referentes a los temas indicados, ahora queda el proceso de procesamiento y exportación de los datos, para futuros análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como podemos observar, obtuvimos alrededor de 600 tweet en 25 min, la gran mayoría referente al tema de interés.\n",
    "\n",
    "# Continuamos con el procesamiento preliminar de los datos\n",
    "\n",
    "# Procesamos los datos extraídos\n",
    "dfProcesado=procesarTexto(df,\"es\")\n",
    "\n",
    "# Exportamos los datos en diferentes formatos, los cuales se almacenarán en la ruta indicada, en este caso en la \n",
    "# misma donde se está ejecutando la aplicación\n",
    "exportToEXCEL(dfProcesado,\"Datos\")\n",
    "exportToCSV(dfProcesado,\"Datos\")\n",
    "exportToTXT(dfProcesado,\"Datos\")\n",
    "exportToJSON(dfProcesado,\"Datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaz Gráfica\n",
    "El proceso de extracción de datos, en tiempo real, desde el API de Twitter se puede realizar completamente desde el script del júpiter notebook, implementando las funciones explicitadas anteriormente, sin embargo se desarrolló una pequeña interfaz para facilitar el proceso de interacción entre la herramienta y el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_AWESOME = \"https://use.fontawesome.com/releases/v5.7.2/css/all.css\"\n",
    "app = JupyterDash(external_stylesheets=[dbc.themes.BOOTSTRAP,FONT_AWESOME], meta_tags=[{'name': 'viewport',\n",
    "                            'content': 'width=device-width, initial-scale=1.0'}])\n",
    "\n",
    "PLOTLY_LOGO = app.get_asset_url('logoHorizontal.png')\n",
    "\n",
    "Navbar = dbc.Navbar(\n",
    "    [\n",
    "        html.A(\n",
    "            dbc.Row([\n",
    "                dbc.Col(html.Img(src=PLOTLY_LOGO, height=\"55rem\"),className=\"p-1\"),\n",
    "                dbc.Col(dbc.NavbarBrand(\"\", className=\"ml-2\")),\n",
    "            ],align=\"Center\",no_gutters=True,),\n",
    "            href=\"\"),\n",
    "        dbc.Col([\n",
    "            dbc.Button(\" \",id=\"btnCredenciales\", color=\"primary\", className=\"fas fa-solid fa-lock\",n_clicks=0),\n",
    "            dbc.Modal(\n",
    "            [\n",
    "                dbc.ModalHeader(\"Token Auntenticación Twitter\"),\n",
    "                dbc.ModalBody([\n",
    "                    dbc.Input(id=\"tokenUser\", placeholder=\"Ingrese usuario twitter\", className=\"m-2\"),\n",
    "                    dbc.Input(id=\"token\", placeholder=\"Ingrese Token de autenticación\",className=\"m-2\"),\n",
    "                    html.Div(id='TokenValido',className=\"m-2 text-center\")\n",
    "                ]),\n",
    "                dbc.ModalFooter([\n",
    "                    dbc.Row([\n",
    "                        dbc.Button(\"Cerrar\", id=\"BtnCerrar\", color=\"danger\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        dbc.Button(\"Test\", id=\"BtnTest\", color=\"info\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        dbc.Button(\"Guardar\", id=\"BtnGuardar\", color=\"primary\",className=\"text-center ml-2\", n_clicks=0),\n",
    "                        \n",
    "                    ])                    \n",
    "                ]),\n",
    "            ],\n",
    "            id=\"modal\",\n",
    "            is_open=False,\n",
    "        ),\n",
    "        ],className=\"text-right\"),\n",
    "    ],\n",
    "    id=\"Navbar\",\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    ")\n",
    "@app.callback(\n",
    "    Output(\"modal\", \"is_open\"),\n",
    "    [Input(\"btnCredenciales\", \"n_clicks\"), Input(\"BtnCerrar\", \"n_clicks\"),Input(\"BtnGuardar\", \"n_clicks\")],\n",
    "    [State(\"modal\", \"is_open\"),State(\"token\", \"value\")],\n",
    ")\n",
    "def toggle_modal(btnCredenciales,BtnCerrar,BtnGuardar,is_open,token):\n",
    "    if BtnGuardar > 0:\n",
    "        if len(token):\n",
    "            GuardarToken(token)\n",
    "        return not is_open\n",
    "    elif btnCredenciales > 0 or BtnGuardar > 0:\n",
    "        return not is_open\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"TokenValido\", \"children\"),\n",
    "    [Input(\"BtnTest\", \"n_clicks\")],\n",
    "    [State(\"token\", \"value\"),State(\"tokenUser\", \"value\")],\n",
    ")\n",
    "def validarToken(BtnTest,token=\"\",tokenUser=\"\"):\n",
    "    if BtnTest > 0:\n",
    "        if token !=None and tokenUser !=None and len(token) > 0 and len(tokenUser) > 0:\n",
    "            GuardarToken(token,tokenUser)\n",
    "            if \"@\" in tokenUser:\n",
    "                tokenUser = tokenUser.replace(\"@\",\"\")\n",
    "            if validarUsuario(tokenUser):\n",
    "                return \"Token valido.\"\n",
    "            else:\n",
    "                return \"Token no valido.\"\n",
    "        return \"Introducir los datos solicitados.\"\n",
    "            \n",
    "#Componenetes parametros generales\n",
    "\n",
    "# idiomo\n",
    "idioma = dbc.Col([\n",
    "            dbc.Label(\"Idioma:\",html_for=\"lengtweet\",width=12, className=\"p-0\", style={\"fontSize\":\"16px\"}),\n",
    "            dbc.RadioItems(options=[{\"label\": \"Ingles\", \"value\": \"en\"},{\"label\": \"Español\", \"value\": \"es\"}],\n",
    "                value=\"en\",id=\"lengtweet\",inline=True)\n",
    "            ],width=6)\n",
    "\n",
    "# retweet\n",
    "retweet = dbc.Col([\n",
    "            dbc.Label(\"\", html_for=\"retweet\", width=12,className=\"p-0\"),\n",
    "            dbc.Checklist(options=[{\"label\": \"¿Retweets?\", \"value\": True}],value=False,id=\"retweet\",inline=True,switch=True)\n",
    "            ],width=6)\n",
    "\n",
    "#Periodicidad\n",
    "SelectorEjecucion = dbc.Col([\n",
    "                dbc.Label(\"Formas de ejecucíon:\", html_for=\"ejecucion\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[\n",
    "                        {\"label\": \"Cantidad de Tweets\", \"value\": 1},\n",
    "                        {\"label\": \"Tiempo de ejecución\", \"value\": 2},\n",
    "                    ],id=\"ejecucion\",placeholder=\"Seleccionar\")\n",
    "                ],width=12,style={\"paddingLeft\": \"15px\", \"marginTop\": \"15px\",\"marginBottom\":\"15px\"})\n",
    "@app.callback(\n",
    "    [Output('CantTweetCol', 'style'),Output('TiempoTweetCol', 'style')],\n",
    "    Input('ejecucion', 'value')\n",
    ")\n",
    "def MostrarTiempoEjecucion(value):\n",
    "    \"\"\"\n",
    "        Esta función muetra la forma de periodicidad que se desea ejecutar\n",
    "        Parámetros:\n",
    "                value: integer\n",
    "                    Indice asociado  la opcion selecionada (cantidad de tweets=1, timepo ejecucion = 2)\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                palabras :stylo para mostrar o ocultar el campo\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> MostrarTiempoEjecucion(1)\n",
    "                    [{\"display\": \"block\"},{\"display\": \"none\"}]\n",
    "    \"\"\"\n",
    "    if value == 1:\n",
    "        return [{\"display\": \"block\"},{\"display\": \"none\"}]\n",
    "    elif value == 2:\n",
    "        return [{\"display\": \"none\"},{\"display\": \"block\"}]\n",
    "    else:\n",
    "        return [{\"display\": \"none\"},{\"display\": \"none\"}]\n",
    "        \n",
    "\n",
    "#Cantidad de tweet\n",
    "cantidadTweet =dbc.Col([\n",
    "                    dbc.Label(\"Cantidad de Tweets:\", html_for=\"CantTweet\", width=12,className=\"p-0\"),\n",
    "                    dbc.Input(type=\"number\", id=\"CantTweet\", placeholder=\"0\",required=False,style={\"fontSize\":\"12px\"}),\n",
    "                ],width=12,style={\"display\": \"none\",\"marginTop\": \"10px\",\"marginBottom\":\"10px\"},id=\"CantTweetCol\")\n",
    "\n",
    "#Ejecución por tiempo\n",
    "TiempoTweet = dbc.Col([\n",
    "                    dbc.Label(\"Tiempo de ejecución:\", html_for=\"TiempoTweet\", width=12,className=\"p-0\"),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetDias\", placeholder=\"Días\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetHoras\", placeholder=\"Horas\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                        dbc.Col([dbc.Input(type=\"number\", id=\"TiempoTweetMin\", placeholder=\"Min\",required=False,style={\"fontSize\":\"12px\"})],width=4),\n",
    "                    ],id=\"TiempoTweet\")\n",
    "                ],width=12, style={\"display\": \"none\",\"marginTop\": \"10px\",\"marginBottom\":\"10px\"},id=\"TiempoTweetCol\")\n",
    "\n",
    "#Formularios parametros generales \n",
    "formularioParamGenerales= dbc.FormGroup([\n",
    "                            dbc.Row([idioma,retweet,SelectorEjecucion,cantidadTweet,TiempoTweet],className=\"m-3\")\n",
    "                          ])\n",
    "\n",
    "CardformularioParamGenerales =dbc.Card([\n",
    "                dbc.CardHeader(\n",
    "                    html.H2(\n",
    "                        dbc.Button(f\"Parametros Generales\",color=\"link\",id={'type': 'btnReglaToggle','index': 54321},n_clicks=0,))),\n",
    "                        dbc.Collapse(formularioParamGenerales,id={'type': 'collapse','index': 54321},is_open=False,),\n",
    "            ])\n",
    "\n",
    "form = dbc.Form([CardformularioParamGenerales],)\n",
    "\n",
    "#Reglas\n",
    "# Formulario de reglas\n",
    "\n",
    "def CrearForm(i):\n",
    "    \"\"\"\n",
    "        Esta función define la estructura interna del formulario que comforma una regla.\n",
    "        Parámetros:\n",
    "                i: integer\n",
    "                Indice asociado a la regla recien creada.\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                palabras : Estructura HTML (string)\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> CrearForm(0)\n",
    "                    la salida es el HTML resultante, sutituyendo el valir de i pasado como parametro.\n",
    "    \"\"\"\n",
    "    palabras = dbc.Form([\n",
    "        dbc.FormGroup([\n",
    "            dbc.Label(\"Nombre regla:\", html_for={'type': 'NombreRegla','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\",id={'type': 'NombreRegla','index': i}, \n",
    "                    placeholder=\"Ingrese nombre de la regla\",style={\"fontSize\":\"12px\"}\n",
    "                ),width=12\n",
    "            ),\n",
    "            dbc.Label(\"Palabras a incluir:\", html_for={'type': 'palabrasIncluidas','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\", \n",
    "                          id={'type': 'palabrasIncluidas','index': i}, \n",
    "                          placeholder=\"Ingrese lista de palabras separadas por coma ','\",style={\"fontSize\":\"12px\"}\n",
    "                ),\n",
    "                width=12),\n",
    "            dbc.Label(\"Palabras a Excluir:\", html_for={'type': 'palabrasExcluidas','index': i}, width=12),\n",
    "            dbc.Col(\n",
    "                dbc.Input(type=\"text\",id={'type': 'palabrasExcluidas','index': i},\n",
    "                          placeholder=\"Ingrese lista de palabras separadas por coma ','\",\n",
    "                          style={\"fontSize\":\"12px\"}\n",
    "                ),width=12,\n",
    "            ),\n",
    "            dbc.Row([\n",
    "                dbc.Button( \"Test\", id={'type': 'BtnProbarRegla','index': i},color=\"info\", className=\"mr-2\",n_clicks=0),\n",
    "                dbc.Button( \"Borrar\", id={'type': 'BtnBorrarRegla','index': i},color=\"danger\", className=\"mr-2\",n_clicks=0)\n",
    "            ],className=\"p-2\", style={\"marginLeft\":\"22rem\"}),\n",
    "            dbc.Col(html.Div(id={'type': 'SalidaRegla','index': i}),width=12)\n",
    "        ],row=True),\n",
    "    ],className=\"p-2\")\n",
    "    return palabras\n",
    "\n",
    "# callback crearRegla #\n",
    "# Permite probará cada una de las reglas haciendo click en el botón BtnProbarRegla\n",
    "# que se encuentra dentro del formulario de cada regla, la finalidad es evaluar si \n",
    "# la regla funciona como es de esperar, en casa de que no podemos reajustar dicha regla\n",
    "# antes de procesar todo el conjunto para la creación del dataset final.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output({'type': 'SalidaRegla', 'index': MATCH}, 'children'),\n",
    "    Input({'type': 'BtnProbarRegla', 'index': MATCH}, \"n_clicks\"),\n",
    "    State({'type': 'NombreRegla', 'index': MATCH}, \"value\"),\n",
    "    State({'type': 'palabrasIncluidas', 'index': MATCH}, \"value\"),\n",
    "    State({'type': 'palabrasExcluidas', 'index': MATCH}, \"value\"),\n",
    ")\n",
    "def crearRegla(n_clicks,mombreRegla,palabrasIncluidas,palabrasExcluidas,lengtweet=\"en\",CantTweet=10,retweet=False):\n",
    "    if n_clicks > 0:\n",
    "        consulta=\"\"\n",
    "        if palabrasIncluidas !=None :\n",
    "            #Listas de palabras a buscar, es valido buscar por hashtag (#)\n",
    "            listaPalabras=palabrasIncluidas.split(\",\")\n",
    "            if len(listaPalabras) > 0 and listaPalabras !=None:\n",
    "                consulta=incluirPalabras(listaPalabras,\"OR\")\n",
    "\n",
    "        if palabrasExcluidas !=None :\n",
    "            # Lista de palabras a excluir\n",
    "            listaPalabrasExcluidas=palabrasExcluidas.split(\",\")\n",
    "            if len(listaPalabrasExcluidas) > 0:\n",
    "                consulta+=\" {}\".format(excluirPalabras(listaPalabrasExcluidas))\n",
    "\n",
    "            consulta+=\" {}\".format(tweetIdioma(lengtweet))\n",
    "            consulta+=\" {}\".format(tweetRetweet(retweet))\n",
    "            reglas=obtenerReglas()\n",
    "            borrarReglas(reglas)\n",
    "            crearReglas(rules_value=consulta, tag_value=mombreRegla)\n",
    "            obtenerTweets(cantTweets=CantTweet,minutos=0,dias=0)\n",
    "\n",
    "            return \"Finalizado\"\n",
    "\n",
    "\n",
    "def CrearListasReglas(i):\n",
    "    \"\"\"\n",
    "        Esta función define la estructura html para cada regla.\n",
    "        Parámetros:\n",
    "                i: integer\n",
    "                Indice asociado a la regla recine creada.\n",
    "            ----------------------------------------------------------------------------------   \n",
    "            Return\n",
    "                Estructura HTML (string)\n",
    "            ----------------------------------------------------------------------------------\n",
    "            Ejemplo:\n",
    "                >>> CrearListasReglas(0)\n",
    "                    dbc.Card([\n",
    "                        dbc.CardHeader(\n",
    "                            html.H2(\n",
    "                                dbc.Button(f\"Regla #1\",color=\"link\",id={'type': 'btnReglaToggle','index': 1},n_clicks=0,))),\n",
    "                                dbc.Collapse(CrearForm(1),id={'type': 'collapse','index': 1},is_open=False,),])\n",
    "    \"\"\"\n",
    "    return dbc.Card([\n",
    "                dbc.CardHeader(\n",
    "                    html.H2(\n",
    "                        dbc.Button(f\"Regla {i+1}\",color=\"link\",id={'type': 'btnReglaToggle','index': i},n_clicks=0,))),\n",
    "                        dbc.Collapse(CrearForm(i),id={'type': 'collapse','index': i},is_open=False,),\n",
    "            ])\n",
    "\n",
    "# callback AddReglaAccordion #\n",
    "# Añade un formulario de reglas nuevo.\n",
    "\n",
    "@app.callback(\n",
    "    Output('accordion-container', 'children'),\n",
    "    Input('AddRegla', 'n_clicks'),\n",
    "    State('accordion-container', 'children'))\n",
    "def AddReglaAccordion(n_clicks, children):\n",
    "    new_dropdown = CrearListasReglas(n_clicks)\n",
    "    children.append(new_dropdown)\n",
    "    return children\n",
    "\n",
    "# callback AbrirCerrarAccordion #\n",
    "# Funcionalidad netamente estética para poder abrir o cerrar \n",
    "# las reglas creadas.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output({'type': 'collapse', 'index': MATCH}, \"is_open\"),\n",
    "    Input({'type': 'btnReglaToggle', 'index': MATCH}, \"n_clicks\"),\n",
    "    State({'type': 'collapse', 'index': MATCH}, \"is_open\"),\n",
    ")\n",
    "def AbrirCerrarAccordion(n_clicks,is_open):\n",
    "    if n_clicks > 0:\n",
    "        return not is_open\n",
    "\n",
    "# callback ProcesarRegla #\n",
    "# Toma todas reglas ya testadas, la procesa en el api de twitter,\n",
    "# para posteriormente generar el dataset según la data disponibles en este\n",
    "# momento en twitter.\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('tabla-container','children'),Output('cargando','style')],\n",
    "    Input(\"BtnProcesar\", \"n_clicks\"),\n",
    "    State({'type': 'NombreRegla', 'index': ALL}, \"id\"),\n",
    "    State({'type': 'NombreRegla', 'index': ALL}, \"value\"),\n",
    "    State({'type': 'palabrasIncluidas', 'index': ALL}, \"value\"),\n",
    "    State({'type': 'palabrasExcluidas', 'index': ALL}, \"value\"),\n",
    "    State(\"lengtweet\", \"value\"),\n",
    "    State(\"retweet\", \"value\"),\n",
    "    State(\"CantTweet\", \"value\"),\n",
    "    State(\"TiempoTweetDias\", \"value\"),\n",
    "    State(\"TiempoTweetHoras\", \"value\"),\n",
    "    State(\"TiempoTweetMin\", \"value\"),\n",
    "    \n",
    ")\n",
    "def ProcesarRegla(n_clicks,nombreReglaID,nombreRegla,palabrasIncluidas,palabrasExcluidas,lengtweet,retweet,CantTweet=0,TiempoTweetDias=0,TiempoTweetHoras=0,TiempoTweetMin=0):\n",
    "    if n_clicks > 0:\n",
    "        \n",
    "        if retweet == [True]:\n",
    "            retweet=True\n",
    "        elif retweet == []:\n",
    "            retweet=False\n",
    "        \n",
    "        reglas=obtenerReglas()\n",
    "        borrarReglas(reglas)\n",
    "        for regla in nombreReglaID:\n",
    "            index=regla['index']\n",
    "            consulta=\"\"\n",
    "            if palabrasIncluidas[index] !=None :\n",
    "                #Listas de palabras a buscar, es valido buscar por hashtag (#)\n",
    "                listaPalabras=palabrasIncluidas[index].split(\",\")\n",
    "                if len(listaPalabras) > 0:\n",
    "                    consulta=incluirPalabras(listaPalabras,\"OR\")\n",
    "\n",
    "                # de esta forma se determinana las frases y van separadas por coma en caso de que se quieran incluir\n",
    "                #listafrases=[w for w in listaPalabrasExcluidas if \" \" in w]\n",
    "\n",
    "            if palabrasExcluidas[index] !=None :\n",
    "                # Lista de palabras a excluir\n",
    "                listaPalabrasExcluidas=palabrasExcluidas[index].split(\",\")\n",
    "                if len(listaPalabrasExcluidas) > 0:\n",
    "                    consulta+=\" {}\".format(excluirPalabras(listaPalabrasExcluidas))\n",
    "            \n",
    "            consulta+=\" {}\".format(tweetIdioma(lengtweet))\n",
    "            consulta+=\" {}\".format(tweetRetweet(retweet))\n",
    "            crearReglas(rules_value=consulta, tag_value=nombreRegla[index])\n",
    "        \n",
    "        if TiempoTweetHoras!= None and TiempoTweetHoras > 0 :\n",
    "            TiempoTweetMin=TiempoTweetSec*60\n",
    "        else:\n",
    "            TiempoTweetHoras=0\n",
    "            \n",
    "        if TiempoTweetMin == None:\n",
    "              TiempoTweetMin=0\n",
    "                \n",
    "        if TiempoTweetDias == None:\n",
    "              TiempoTweetDias=0\n",
    "        \n",
    "        if CantTweet == None:\n",
    "            Cantidad = 0\n",
    "                \n",
    "        obtenerTweets(cantTweets=CantTweet,minutos=TiempoTweetMin,dias=TiempoTweetDias,timeoutMin=10)\n",
    "        table = dbc.Table.from_dataframe(CrearTweetDataSet('DataTweet.json'), striped=True, \n",
    "                                         bordered=True, \n",
    "                                         hover=True,\n",
    "                                         responsive=True,\n",
    "                                         className=\"m-3\")\n",
    "        return [table,{\"display\": \"none\"}]\n",
    "    return[\"\",style_cargando]\n",
    "                 \n",
    "    \n",
    "##\n",
    "## CONTENT\n",
    "##\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cargando\", \"children\"),\n",
    "    [Input(\"BtnProcesar\", \"n_clicks\")]\n",
    ")\n",
    "def cargandoData(BtnProcesar):\n",
    "    if BtnProcesar > 0:\n",
    "        cargando=dbc.Spinner(color=\"primary\",spinner_style={\"width\": \"5rem\", \"height\": \"5rem\"})\n",
    "        return cargando\n",
    "\n",
    "    cargando=dbc.Spinner(color=\"primary\",spinner_style={\"width\": \"5rem\", \"height\": \"5rem\"})\n",
    "\n",
    "reglas = html.Div(id='accordion-container', children=[],className=\"\")\n",
    "Btn=dbc.Row([\n",
    "        dbc.Col([dbc.Button( \"Ejecutar\", id=\"BtnProcesar\",color=\"primary\", className=\"mr-2\",n_clicks=0,block=True)]),\n",
    "        dbc.Col([dbc.Button( \"Añadir Regla\", id=\"AddRegla\", className=\"mr-2\",n_clicks=0,block=True),]),\n",
    "        dbc.Col([dbc.Button( \"Exportar Ficheros\", id=\"BtnExportar\", className=\"mr-2\",n_clicks=0,block=True),]),\n",
    "    ],className=\"m-3\")\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"DivExportar\", \"children\"),\n",
    "    [Input(\"BtnExportar\", \"n_clicks\")]\n",
    ")\n",
    "def cargandoData(BtnExportar):\n",
    "    if BtnExportar > 0:\n",
    "        df=CrearTweetDataSet(\"DataTweet.json\")\n",
    "        dfProcesado=procesarTexto(df,\"es\")\n",
    "        #Exportamos los datos en diferentes formatos\n",
    "        exportToEXCEL(dfProcesado,\"Datos\")\n",
    "        exportToCSV(dfProcesado,\"Datos\")\n",
    "        exportToTXT(dfProcesado,\"Datos\")\n",
    "        exportToJSON(dfProcesado,\"Datos\")\n",
    "        return \"Ficheros exportados correctamente\"\n",
    "\n",
    "style_cargando ={\n",
    "    \"height\": \"100vh\",\n",
    "    \"display\": \"flex\",\n",
    "    \"justifyContent\": \"center\",\n",
    "    \"alignItems\": \"center\",    \n",
    "}    \n",
    "\n",
    "content = dbc.Row([\n",
    "        dbc.Col([form,reglas,Btn],className=\"m-0 p-0\",width=4,style={\"backgroundColor\":\"#f8f8f8\", }),\n",
    "        dbc.Col([html.Div(id=\"DivExportar\"),html.Div(id='cargando',style=style_cargando),html.Div(id=\"tabla-container\",style={\"height\":\"100vh\", \"overflowY\": \"auto\",\"overflowX\": \"hidden\"})],width=8)\n",
    "    ],id=\"Content\",className=\"container-fluid\", style={\"height\":\"100vh\"})\n",
    "\n",
    "##\n",
    "## MAIN HTML\n",
    "##\n",
    "\n",
    "body = dbc.Container([Navbar,content], className=\"col-12 p-0\",style={\"height\":\"100%\", })\n",
    "app.layout=body\n",
    "\n",
    "# Run app and display result inline in the notebook\n",
    "#app.run_server(mode='inline')\n",
    "app.run_server(mode='external',debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
